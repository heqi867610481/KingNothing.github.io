<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title></title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title">
<meta property="og:url" content="https://heqi867610481.github.io/KingNothing.github.io/index.html">
<meta property="og:site_name">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Meiyi Jiang">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="https://heqi867610481.github.io/KingNothing.github.io/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/">Home</a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://heqi867610481.github.io/KingNothing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-paper5" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/" class="article-date">
  <time datetime="2020-05-22T02:37:58.000Z" itemprop="datePublished">2020-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/">论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Crimson Bow and Arrow – Epica</p>
<h1 id="1-论文总体思路"><a href="#1-论文总体思路" class="headerlink" title="1 论文总体思路"></a>1 论文总体思路</h1><p>现存的输入不可知的对抗性扰动展示了一种有趣但现在无法解释的视觉模式。本篇论文引入了一种结构化的程序噪声函数来生成通用对抗扰动（UAP）的方法。这种方法在计算机图形化中广泛应用并且被设计为可参数化的。这种方式生成的噪声图样和现存的通用对抗扰动在视觉上有着相似性。此方法揭示了现在流行的DCN架构（比如Inception v3和YOLO v3）的系统脆弱性。此外，过程中用了贝叶斯优化来有效地学习程序噪音参数来构建低代价无目标的黑盒攻击。进一步的，启发了输入不可知的防御来提高模型对对抗扰动的稳定性。攻击方法的普遍性暗示了DCN可能对低层级类别不可知的特征的聚合很敏感。<br>实验过程，首先在大规模ImageNet classifier上进行黑盒攻击，误分类率高达98.3%。攻击也迁移到了目标检测任务中，结果表示对YOLO v3目标检测器的检测物体有模糊效果。<br>论文创新点：1）第一个对模型不可知黑盒生成通用对抗扰动的方法。2）利用贝叶斯优化来有效加强黑盒攻击。他提高了5折随机参数选择的查询效率，并且效果要好于现在流行的L-BFGS优化算法。3）实验证据表明，程序噪音UAP似乎利用DCN的低层级特征，这一脆弱性可能会被利用创造跨应用的通用对抗性扰动。</p>
<h1 id="2-攻击模型"><a href="#2-攻击模型" class="headerlink" title="2 攻击模型"></a>2 攻击模型</h1><h2 id="2-1-攻击的普遍性（generalizability）"><a href="#2-1-攻击的普遍性（generalizability）" class="headerlink" title="2.1 攻击的普遍性（generalizability）"></a>2.1 攻击的普遍性（generalizability）</h2><p>generalizability衡量了两个方面的事情，一个是可移植性，另一个是universality。Input-specific类型的对抗扰动是针对给定的输入以及模型，是既不transferability，也不universality的。Transferable对抗扰动指，加到同一个输入上，能够使不同的模型误分类，一方面加大了攻击面，另一方面也为黑盒攻击找替代模型奠定基础。Universal的扰动指的是，对于一个数据集的大部分图片，添加上同一个扰动都可以造成误分类。Cross-model universal的扰动就是既transferability又universal。</p>
<h2 id="2-2-攻击类型"><a href="#2-2-攻击类型" class="headerlink" title="2.2 攻击类型"></a>2.2 攻击类型</h2><p>前提是对于躲避攻击，认为攻击者可以对模型进行输入并得到输出。白盒攻击：对模型架构，训练集，参数的全知识。灰盒攻击：攻击者可以构造相似规模的替代模型，并且能够得到相似的数据集（此方法也可用于黑盒设置）。黑盒攻击：攻击者不知道目标模型也无法得到替代数据集，与目标模型唯一的互动是“query”它。由于黑盒攻击依赖于做大量query来获取信息，这就增加了被发现的几率。有一些黑盒攻击方案应用了零阶优化和梯度估计，但是query次数仍然过多。目前查询次数最少的一种方式用了匪帮优化框架，在ImageNet数据集的 每张图片平均约1000次查询。</p>
<h1 id="3-程序噪声"><a href="#3-程序噪声" class="headerlink" title="3 程序噪声"></a>3 程序噪声</h1><p>程序噪声函数是用来生成图片模式的算法，通常用于创建自然细节以增强视频和图形制作中的图像。具有快速，可扩展，低内存占用等特点。<br>现存的通用对抗扰动（UAP），展现出的很有趣的一点是，他们的“通用性”，揭示了更广泛或者与类无关的特征，而机器学习算法又对此很敏感。论文做的假设就是程序噪声既然视觉上和那些UAP很相像，就也能起到UAP的作用。而且程序噪声生成的参数相对较少，可以负担得起黑盒攻击的query。程序噪声可分为3类：lattice gradient noise，sparse convolution noise和explicit noise。<br>lattice gradient noise通过在网格的整数点上随机插值或者梯度生成噪声，Perlin噪声是其代表。Sparse convolution noise随机定位并赋权重的核（指图片卷积用到的矩阵）的综合，Gabor noise是其代表。Explicit noise生成过程中，图片被提前生成并存储，这就需要较大的存储空间，因此在本论文的环境不适用。</p>
<h2 id="3-1-Perlin-Noise"><a href="#3-1-Perlin-Noise" class="headerlink" title="3.1 Perlin Noise"></a>3.1 Perlin Noise</h2><p>原理和实现参考链接：<br><a href="https://www.cnblogs.com/mtcnn/p/9412106.html" target="_blank" rel="noopener">https://www.cnblogs.com/mtcnn/p/9412106.html</a><br><a href="https://blog.csdn.net/yolon3000/article/details/76577071" target="_blank" rel="noopener">https://blog.csdn.net/yolon3000/article/details/76577071</a></p>
<h2 id="3-2-Gabor-Noise"><a href="#3-2-Gabor-Noise" class="headerlink" title="3.2 Gabor Noise"></a>3.2 Gabor Noise</h2><h1 id="4-DCN脆弱性实验"><a href="#4-DCN脆弱性实验" class="headerlink" title="4 DCN脆弱性实验"></a>4 DCN脆弱性实验</h1><p>实验数据集来源是the ILSVRC2012 ImageNet分类任务的验证集。测试的DCN架构是VGG-19，ResNet-50，Inception v3和Inception ResNet v2（IRv2），这些都是在ImageNet上预训练好的。此外还有一个IRv2的改进版本：对基于梯度的对抗攻击更鲁棒的调好参数的IRv2（IRv2ens）网络，它与IRv2同架构但是不同参数。<br>关于扰动参数设置，Perlin的噪声参数有：$\lambda$x，$\lambda$y，$\phi$sine和$\Omega$，Gabor的噪声参数有：$\sigma$，$\lambda$，$\omega$和$\xi$。其中，Perlin的$\lambda$x，$\lambda$y，$\phi$sine和Gabor的$\sigma$，$\lambda$是正值，且由图片的边长d来限定。衡量各向同性的$\xi$取值范围在1到12之间，衡量octaves数量的$\Omega$取值范围为1到4，二者都是离散的。$\omega$数值范围0到2$\pi$。<br>关于衡量指标，定义了通用规避率，模型的平均敏感度以及针对特别输入的规避率。实验设置从图片验证集中随机抽出5000张图片，产生的扰动有1000来自Gabor，1000来自Perlin，还有10000来自随机扰动。对于程序噪声而言，1000次对黑盒的查询就足以得到结果。<br>从对实验结果的分析来看，Perlin总体表现比Gabor要好一点。对于Gabor而言，$\lambda$和通用规避率表现出了高相关，其他参数线性相关程度较低。$\lambda$和规避率的相关性表明低频的Gabor噪声图像意味着高通用规避。对于Perlin而言，规避率和octaves的数量$\Omega$有着中等程度的负相关，和$\phi$sine有着较高的正相关。这说明高频的Perlin噪声图样有着更高的规避率，然后具有较少细节和曲率的图样可能也能取得较高的规避率。IRv2ens的表现似乎都是都低频噪声图样更敏感，这可能是因为模型被训练的可以抵抗基于梯度的攻击，可能更多地是高频的扰动。但对其他的模型，Gabor和Perlin的噪声频率表现出了和规避率相反的相关，这种差异可能说明了这些噪声图样有不同的特征。<br>对于模型的敏感度而言，可以观察到对于每个模型，容易受两种噪声图样影响的都是相似的一群输入，模型也是对几乎同一批输入的程序噪声更敏感。<br>Perlin的对分类的影响较Gabor而言更有定向性，这可能是因为Perlin噪声对于特定的类具有更大的偏差，但是Gabor更无差别。<br>其他的一些讨论：1）似乎DCN的分类结果更依赖于质地（texture）而不是形状，好像对质地更有偏差。2）大多数有着高规避率的扰动没有对某一类的偏向，这可能暗示了UAP利用了更低层级的特征。程序噪声产生的视觉效果上最相近的是Singular Vector Attack（文献30），而SVA针对的是网络的浅层来生成对抗噪声。而且在自然图片上训练的DCN学习到的卷积filter视觉上也与Gabor核和色斑很相似（文献48，76）。Gabor噪声看起来 像是浅层特征的简单集合，而Perlin噪声似乎是浅层特征的更复杂的混合。这可能解释了为什么Perlin噪声的攻击比Gabor效果好。3）程序噪声在各个模型之间的迁移性比较好可能是因为他们有着同样的训练集，学习算法（反向传播），架构中的相同组件（卷积层）。这暗示了这些模型共有一些输入不可知的脆弱性。4）迁移学习的广泛应用可能有些安全隐患，因为训练过程中最前几层的参数被固定，保留了低层次的特征。准确衡量迁移学习后的模型对相同攻击的脆弱性的程度是未来的一个研究方向。5）本论文研究内容和和其他的对抗样本生成方式不同，其他的比如贝叶斯网络，GAN，可变自动编码器（VAE）等，都需要额外的训练模型或网络。而且本论文中的方法参数搜索维度较小，只有4个，而其他的方法是整个图片的整个输入空间。当然代价是这种方法没有捕捉到这个范围之外的对抗扰动。6）其他的一个缺点是衡量扰动公式中用到了l无穷范式，lp范式的一个缺点就是同样的lp范式似乎对高频的pattern更视觉可见。频率可以被用作一个额外的限制，并且发展一个人类直觉的更好表达来代替lp范式，这也是未来的研究方向。</p>
<h1 id="5-黑盒攻击的优化和比较"><a href="#5-黑盒攻击的优化和比较" class="headerlink" title="5 黑盒攻击的优化和比较"></a>5 黑盒攻击的优化和比较</h1><p>对于针对专门输入的和通用的分类器，比较了几种黑盒优化技巧，最终证明贝叶斯优化对于参数的确定是一种很有效的方式。</p>
<h2 id="5-1-贝叶斯优化"><a href="#5-1-贝叶斯优化" class="headerlink" title="5.1 贝叶斯优化"></a>5.1 贝叶斯优化</h2><p>贝叶斯优化是一种序列优化算法用来给黑盒目标函数寻找优化参数。贝叶斯优化法由一个概率替代模型和一个指引查询的获得函数组成。概率替代模型通常是一个高斯过程，获得函数通常用高斯回归，通常在每次查询后更新关于目标函数参数的置信。</p>
<h3 id="5-1-1-高斯过程"><a href="#5-1-1-高斯过程" class="headerlink" title="5.1.1 高斯过程"></a>5.1.1 高斯过程</h3><h3 id="5-1-2-获得函数"><a href="#5-1-2-获得函数" class="headerlink" title="5.1.2 获得函数"></a>5.1.2 获得函数</h3><h2 id="5-2-实验设置"><a href="#5-2-实验设置" class="headerlink" title="5.2 实验设置"></a>5.2 实验设置</h2><p>使用Inception v3模型，训练集和验证集都来源于ILSVRC2012。实验将贝叶斯优化和L-BFGS算法相比较，L-BFGS是一种常应用于黑盒算法和机器学习的拟牛顿优化算法。由于程序噪声函数是不可微分的，采用有限差分近似来估计梯度。这种梯度近似和用在其他黑盒攻击（比如零阶攻击）上的优化算法很像，但是被应用在一个更小的搜索空间内。当L-BFGS收敛，很可能是找到了一个局部最优解，这时就用一个不同的随机初始值来重新开始优化，当达到查询次数限制时停止，选择找到的最优值。实际实验的时候，这个查询限制设置为1000，但往往收敛速度都很快，不用1000次查询。</p>
<h2 id="5-3-针对特定输入的黑盒攻击"><a href="#5-3-针对特定输入的黑盒攻击" class="headerlink" title="5.3 针对特定输入的黑盒攻击"></a>5.3 针对特定输入的黑盒攻击</h2><p>这个实验针对模型原来能正确分类的图片中的一个子集，希望可以最大化子集的规避率，衡量指标有成功率和平均查询次数。在这个实验中，允许攻击者得到模型的输出概率向量，并使用松散GP来更好的对贝叶斯优化进行缩放，因为标准的GP是是对观察次数按立方缩放。实验结果来看，贝叶斯优化法的结果很优秀，平均7次查询就能达到91.6%的成功率，L-BFGS表现很差，他会陷在局部最优之中浪费掉很多查询机会，需要在不同的初始点重启多次。</p>
<h2 id="5-4-和Ilyas等人成果的比较"><a href="#5-4-和Ilyas等人成果的比较" class="headerlink" title="5.4 和Ilyas等人成果的比较"></a>5.4 和Ilyas等人成果的比较</h2><p>Ilyas等人的做法是把攻击描述成一个梯度估计的问题（就像基于梯度的白盒攻击），然后用一个匪帮优化的框架来解决。比较结果是当限制查询次数在千以内的话，程序噪声攻击很明显的优于他们的做法。大多数的方法是在图片所有维度进行搜索，几乎在足够的查询下是一定可以找到对抗样本的。bandit方法为了减少查询次数，对成功率有所牺牲，而程序噪声方法做的程度更深。当然程序噪声的做法也可以通过引入更多参数（比如使用不同的颜色图），来扩大搜索空间，但是这可能破坏它天然的高通用规避率。</p>
<h1 id="6-程序噪声攻击YOLO-v3"><a href="#6-程序噪声攻击YOLO-v3" class="headerlink" title="6 程序噪声攻击YOLO v3"></a>6 程序噪声攻击YOLO v3</h1><p>目标检测模型YOLO v3属于SSD，意味着对输入图片一遍就得到预测结果，而比如FastR-CNN或FasterR-CNN，他们是基于region proposals的，处理速度并不如SSD类型的。数据集使用MS COCO数据集。这部分实验没有进一步应用优化算法，而是和4部分的实验比较相像。实验结果表明攻击的高成功率更有可能是由模型对扰动的敏感性引起的，而不是对质地的偏差。</p>
<h1 id="7-未来方向总结"><a href="#7-未来方向总结" class="headerlink" title="7 未来方向总结"></a>7 未来方向总结</h1><p>1）对于其他应用（语音识别，NLP，强化学习）寻找程序噪声的类似物。作为开始，可以通过寻找使隐藏层差别最大化的扰动开始，比如通过Singular Vector Attack或者对DCN的浅层特征视觉化来推断模型学到的浅层特征。<br>2）可以最小化小扰动的影响的输入不可知的防御可能在降低模型的敏感度上很有效，而不用专门针对各种攻击来训练。比如论文最后尝试了一下降噪这个手段。用特别的过滤器来降噪是信号处理的一个通常的预处理手段。比如中值滤波。中值滤波是一种平滑操作，将每个输入的值代替为他邻居们的值的中位数，通常既保留了边，也移除了噪声。这种做法平滑了高频噪声，而高频噪声又和Perlin噪声的规避率有很高相关。论文做了实验，在Inception v3模型前加了中值滤波过滤器的预处理步骤。实验结果规避率有所下降，尽管没有下降很多。未来的工作希望可以尝试别的降噪算法，比如模型压缩，Jacobian正则化等。<br>附：图像降噪算法总结和具体实现<br>[<a href="https://blog.csdn.net/u013185349/article/details/87934745][https://blog.csdn.net/u013185349/article/details/87934745]" target="_blank" rel="noopener">https://blog.csdn.net/u013185349/article/details/87934745][https://blog.csdn.net/u013185349/article/details/87934745]</a><br>[<a href="https://github.com/wenbihan/reproducible-image-denoising-state-of-the-art][https://github.com/wenbihan/reproducible-image-denoising-state-of-the-art]" target="_blank" rel="noopener">https://github.com/wenbihan/reproducible-image-denoising-state-of-the-art][https://github.com/wenbihan/reproducible-image-denoising-state-of-the-art]</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/" data-id="ckanu4eaq0000skcp11eldwxc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-paper4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/" class="article-date">
  <time datetime="2020-05-17T11:47:27.000Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：King Nothing – Metallica （今天没打鼓，良心痛。看一篇不太了解的领域的论文，换下口味。）</p>
<h1 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h1><p>这篇论文是关于对基于图的分类的攻击的（好绕）。基于图的分类大致可分为这两种：Collective Classification和图神经网络（GNN）。然后这篇论文是针对Collective Classification这一类的。论文中说现在对抗攻击大多都是针对非图的算法，就算是针对图的，也是GNN比较多。对于某些特定的安全问题，Collective Classification效果要好一点 。在这里把论文提到的基于图分类的相关算法都列出学习一下。<br>先说一下数据的结构。给定的是一个图和训练集。图可以是有向图或者无向图。训练集是图上一部分标记为正节点和负节点的节点。基于图的分类就是要预测这些没标记的节点是正是负。</p>
<h2 id="1-1-Collective-Classification"><a href="#1-1-Collective-Classification" class="headerlink" title="1.1 Collective Classification"></a>1.1 Collective Classification</h2><p>Collective Classification基于训练集给每个点定义了一个前声誉得分（prior reputation score），接着给每条边分配或学习权重，然后然后在这个有权重的图里传播前声誉得分，来获得每个节点的后声誉得分（posterior）。后声誉得分被用来给没标签的节点分类。不同的CC方法用不同的方式定义前声誉得分，分配/学习边权重，以及传播前声誉得分。<br>常见的有这么几种：基于RW的，基于LBP的，基于LinLBP的，以及JWP方法。</p>
<h3 id="1-1-1-基于RW的方法"><a href="#1-1-1-基于RW的方法" class="headerlink" title="1.1.1 基于RW的方法"></a>1.1.1 基于RW的方法</h3><p>首先关于前声誉得分，给标记为正节点的赋值为1，标记为负节点的赋值为0，还没标记的节点赋值为0.5。此外关于边的权重，赋值为同样的值或者赋值为用节点属性学习到的权重。最后，利用random walk在有权重的图中传播声誉得分。他们迭代的把一个节点的当前名誉得分，根据边的权重，按比例传播给邻居节点。然后节点的新的名誉得分，是邻居们的名誉得分总和。</p>
        
          <p class="article-more-link">
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/" data-id="ckab75xm40000xocpargdd0lg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-paper3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/" class="article-date">
  <time datetime="2020-05-16T02:22:52.000Z" itemprop="datePublished">2020-05-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Heart’s Desire – Dreamtale</p>
<h1 id="1-论文概述"><a href="#1-论文概述" class="headerlink" title="1 论文概述"></a>1 论文概述</h1><p>首先应用FGSM对人脸图片添加扰动，并在在自己训练的不同分类器上测试了效果，以验证可移植性（白盒）。接下来又精心构造了一些攻击算法（偏黑盒），针对的是untargeted黑盒，目的是评估人脸识别领域的DNN的鲁棒性。具体有三种方式：给最优的一个像素改变很大值；给所有像素值改变一个很小值；或者二者结合。最后结果是第二种方式明显要好，而且即使是最高水平的扰动，扰动后的图片也是对于人类可识别的。论文关注的一个问题是：对于人脸识别是否有特别的特征可以让攻击更成功或者更不成功。</p>
<h1 id="2-相关背景"><a href="#2-相关背景" class="headerlink" title="2 相关背景"></a>2 相关背景</h1><p>主要是这里提到了Papernot, et al. 的工作，值得注意下。他们先是有篇论文设计了一种攻击可以误分类到某个特定的类别。并且平均对每个样本的输入特征只改动4.02%就能达到97%的攻击成功率。然后他们又发篇论文提出了“Defensive Distillation”的防卫机制来预防对抗攻击。方法是降低对抗样本生成用到的梯度，用一个10^30的因子。论文又提到了目前效果最好的CW基于L2范式的白盒攻击。即使对于应用了“Defensive Distillation”的网络也有极高的攻击成功概率。</p>
<h1 id="3-提到的数据集"><a href="#3-提到的数据集" class="headerlink" title="3 提到的数据集"></a>3 提到的数据集</h1><p>the Extended Yale Face Database B cropped image database。38个人，每人65张照片，共2470张在不同的光照条件下。168x192的灰度图。</p>
<h1 id="4-提到的算法"><a href="#4-提到的算法" class="headerlink" title="4 提到的算法"></a>4 提到的算法</h1><p>FGSM（Fast Gradient Sign Method）。在损失的梯度的方向上加扰动来最大化分类的损失函数。是白盒模型，知道包括分类结果的置信水平，权重，参数这些。</p>
<h1 id="5-实验设计"><a href="#5-实验设计" class="headerlink" title="5 实验设计"></a>5 实验设计</h1><p>先用谷歌的Inception v3 CNN在Yale B数据集上训练了一个模型。用了一个特征提取模型：神经网络的前几层在 ImageNet数据集上训练，学习从原始数据中获得有助于分类的有效特征；然后后面的几层被训练输出分类，其输入是用户提供的特定训练集的提取的特征。（这个操作有点迷，是通用的操作吗？）（TensorFlow实现）<br>首先是FGSM部分。用FGSM算法针对Papernot, et al.设计的分类器模型，用的数据集是本篇paper之前提到的并处理好的。这样生成扰动后数据来测试他们自己的模型，目的是测试可移植性，发现效果不佳，不如他们自己设计的攻击。<br>接下来就是他们自己设计的攻击啦。</p>
<h2 id="5-1-方式一"><a href="#5-1-方式一" class="headerlink" title="5.1 方式一"></a>5.1 方式一</h2><p>这里主要想找一下是否存在这样一个像素点，单单改变这个像素点的值比改变其他像素点对分类的置信水平影响相对比较大。于是他们是这么做的。对每一个图片，分成56个24x24的格子。对于每一个格子，每次随机找个一像素值改变（by128mod255）然后送去看分类效果。对56次都跑完之后，选使特定类置信水平下降最多的一个（攻击A）或者两个（攻击B）像素点。除了A和B，还有攻击C，C是在攻击A的基础上再迭代一次重复这个过程。</p>
<h2 id="5-2-方式二"><a href="#5-2-方式二" class="headerlink" title="5.2 方式二"></a>5.2 方式二</h2><p>就是改变每一个像素点的方式。一开始做的改变都是同一个方向的，意思就是都变量或者都变暗（过程是迭代的），但结果这样效果不佳，往往到最后人类就不可识别了。后来就采用一种棋盘式方法，相邻像素一个加一个减。根据随机改变的数值的范围不同，确定了攻击DEF。（D改变30<del>60加或减，E60</del>90，F120~150。）值得注意的是大多数图片在较小的变动范围内都能取得较好的误分类结果，但是仍有少数图片在变动较大时也不能导致误分类。如果分类器当时训练的时候数据集更大更多样一些，这种情况会少。</p>
<h2 id="5-3-方式三"><a href="#5-3-方式三" class="headerlink" title="5.3 方式三"></a>5.3 方式三</h2><p>二者结合的方式，先实行攻击D，然后在生成的攻击图片基础上实行攻击B（称为攻击G）。</p>
<h1 id="6-结果评估"><a href="#6-结果评估" class="headerlink" title="6 结果评估"></a>6 结果评估</h1><p>衡量攻击的成功与否有两个指标：1）ConfA：攻击样本输出结果的正确分类的置信水平下降程度，相比于正常样本的置信水平。2）误分类百分比：就是测试集里实施攻击后误分类的样本占比。<br>实验结果是改变大多数比改变一两个效果明显好，耗时也短。但是paper贼心不死的说，也许用一种更好的像素搜寻方法，基于单个像素点的攻击可能会更成功。因为可能更能找到局部最优扰动。攻击方式一虽然不太能导致误分类，但是确实使置信水平大幅下降。这种方式现实生活中可能也不那么实际，因为攻击者往往得不到模型的置信水平返回。paper最后也没找到人脸哪部分区域的像素值改变对置信水平影响更大。<br>攻击二会让图片看起来有点像素化，而且在改动比较大的范围内，会有肉眼可见的变化，虽然还能看出来是个人脸。<br>攻击三效果比D好了一点点而已，甚至没超过E。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/" data-id="cka9n3cs80000d8cp8wom47k8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-paper2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/" class="article-date">
  <time datetime="2020-05-15T11:23:24.000Z" itemprop="datePublished">2020-05-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/">论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Swan Lake – Dark Moor（这溢出耳机的黑魔法气息！）</p>
<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h1><p>论文的源码<a href="https://gitlab.com/EAVISE/adversarial-yolo" target="_blank" rel="noopener">https://gitlab.com/EAVISE/adversarial-yolo
</a><br>首先说这个论文应该是把对抗样本应用到real-world的一个例子。他生成了一个patch（40cm x40cm）可以打印出来挂到身上来躲避person detection。一个难点或者创新点是人类具有intra-class variety，就是说同属于人类看起来差别很大，对比一下路边的stop路标。而且人的background也啥都有，而路标的背景就比较固定。论文针对的是YOLOv2物体检测。</p>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h1><p>首先关于对分类的对抗攻击，按历史列出了几个比较重要的思路。1）Szegedy et al. 通过稍微改变图片的像素值使得分类错误，找的是最优；2）Goodfellow et al. 通过faster gradient sign，使得更快生成对抗图片样本。找的不是最优，而是在一堆图片中找个能攻击的就好；3）CW；4）Brown et al. 的做法感觉和这篇论文比较接近。也是生成patch贴在图片上（digitally），而且为了应对intra-class variety，用了一堆图片实验；5）Evtimov et al. 针对stop路标做了相似的real-word攻击；6）Athalye et al. 把攻击样本3D打印出来了，为了鲁棒性，考虑到了图片有不同的pose和光线变化；7）MoosaviDezfooli 做的对不同detector都很鲁棒的通用的对抗图片。</p>
<h1 id="3-YOLO以及YOLOv2以及SSD"><a href="#3-YOLO以及YOLOv2以及SSD" class="headerlink" title="3 YOLO以及YOLOv2以及SSD"></a>3 YOLO以及YOLOv2以及SSD</h1><h2 id="3-1-YOLO"><a href="#3-1-YOLO" class="headerlink" title="3.1 YOLO"></a>3.1 YOLO</h2><p>YOU ONLY LOOK ONCE！属于一种单点目标检测器（single shot object detectors ）。bounding box，object score，class score经过一遍网络后都直接输出。</p>
<h2 id="3-2-YOLOv2"><a href="#3-2-YOLOv2" class="headerlink" title="3.2 YOLOv2"></a>3.2 YOLOv2</h2><p>YOLOv2结构是全卷积的，图片经过网络后成了小了32倍的输出网格。对于每个网格，有五（默认）个不同纵横比的anchor box，每个anchor box都包括一个向量[x,y,w,h,pobj,p1,…,pn]。x，y是bounding box的中心相对于当前这个anchor box的概率。w，h是bounding box的高和宽；pobj是这个anchor box有物体的概率。pn是通过交叉熵损失得到的第n类的class score。</p>
<h2 id="3-3-SSD"><a href="#3-3-SSD" class="headerlink" title="3.3 SSD"></a>3.3 SSD</h2><h1 id="4-提到的数据集"><a href="#4-提到的数据集" class="headerlink" title="4 提到的数据集"></a>4 提到的数据集</h1><p>Inria<br>MS COCO<br>Pascal VOC </p>
<h1 id="5-loss函数设计以及实验workflow"><a href="#5-loss函数设计以及实验workflow" class="headerlink" title="5 loss函数设计以及实验workflow"></a>5 loss函数设计以及实验workflow</h1><h2 id="5-1-loss函数"><a href="#5-1-loss函数" class="headerlink" title="5.1 loss函数"></a>5.1 loss函数</h2><p>loss函数由三部分组成，最后由参数因子平衡，然后采用Adam优化法。具体的公式见论文。1）Lnps——衡量了patch的不可打印性。对于patch的每一个像素，在打印机可打印的范围内找最相近的颜色，之后求和。2）Ltv——衡量了patch的颜色的平滑性。希望patch颜色过渡平滑，于是对于每个像素点，计算它和横向纵向相邻像素的距离，越低越好。3）Lobj——被贴patch的图像（注意不是patch）被检测到的score的最大值。当然这个值越小越好。这个Loss的具体定义可以采用不同方案，可以最小化人这个分类的概率，可以最小化检测到物体的概率，也可以结合两种。但是第一种方式会导致把被检测物体（人）被认为是其他类，甚至生成的patch会明显像其他分类下的物体（比如泰迪熊），而且换一个没有泰迪熊这种分类的，就降低了可移植性。</p>
<h2 id="5-2-workflow"><a href="#5-2-workflow" class="headerlink" title="5.2 workflow"></a>5.2 workflow</h2><p><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/15/paper2/images/3.png" alt="workflow"><br>在整个优化过程中，神经网络的参数训练好是不变的，仅仅改变patch的像素值。然后因为检测人除了前面提到的长相多种，背景多种之外，还有人的位置不固定所以patch贴的位置不固定这种问题。论文设计的workflow解决了这个问题。首先对于数据集里的图片，都先送到检测器里跑一下，得到人的bounding box。然后在相对于bounding box固定的位置贴当前版本做过小变动的patch。合成的图片一batch一batch的送去检测。有些图片还能检测到人，就用来计算损失函数，然后反向传播优化patch的像素值。论文还提到可以针对特定的场景得到特定的patch，效果比通用的patch要好些。<br>因为patch是要在现实生活中用的，方方正正的打印出来但是到镜头里就会变形，受光线影响什么的。所以为了提升鲁棒性，在patch加到图片前就对patch做了小变动，具体包括随机缩放，随机噪声，随机改变亮度和对比。</p>
<h1 id="6-实验和结论"><a href="#6-实验和结论" class="headerlink" title="6 实验和结论"></a>6 实验和结论</h1><p>除了之前提到的Lobj三种方式，还加了两个对照组，一个是没有patch，一个是随机生成噪声的patch。为这五组实验画了PR曲线图，用画对角线相交的方式确定比较好的working point。最后结果是最小化objection概率的方式效果比较好。在现实生活中的实验，发现patch不在人体中心对结果影响有点大，这是因为在生成patch时，patch的位置都固定在bounding box的中间吧。<br>关于未来方向，一个是鲁棒性 ，一个是可移植性，现在的工作可移植性不太好，如果想移植到一个完全不同的架构上，比如Faster R-CNN。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/" data-id="cka8794px00007scp7la3g2n1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-paper1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/" class="article-date">
  <time datetime="2020-05-14T06:37:01.000Z" itemprop="datePublished">2020-05-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/">论文笔记：1   Face-Off：Adversarial Face Obfuscation</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Dies Irae – Dark Moor（配合食用更佳）（没什么比output同时夹带私货更开心了）</p>
<h1 id="1-论文总体思路"><a href="#1-论文总体思路" class="headerlink" title="1 论文总体思路"></a>1 论文总体思路</h1><p>首先这篇设计的Face-Off针对的是人脸recognition而不是detection。目标是使服务提供者仍然能检测到人脸，但是却把他认错。<br>面临的挑战有 1）现存的对抗攻击多关注于分类器（直接输出分类结果），但是paper解决的问题是针对所谓“metric learning system”，这种人脸识别/验证都是把输入用特征向量表示，然后去找最近的一簇。2）paper面临的是要实现黑盒攻击，而且也不能利用黑盒的输出去生成对抗性样本。<br>对于困难1），解决办法是专门为“metric learning system”设计了两种损失函数。损失函数目的是在得到嵌入向量时就尽量让图片远离正确答案。<br>对于困难2），解决办法是利用移植的办法。先用一个替代模型（白盒）生成对抗样本，然后用一个因子阿尔法a放大扰动。用放大因子也有个好处就是减少了生成对抗样本的时间。<br>这个替代的白盒模型用了两种模型【25】【36】。生成对抗样本的攻击算法也用了两种，即CW和PGD。<br>然后Face-Off的工作流程是这样的：1）收到用户的目标图片；2）识别并分离出脸部；3）调整大小为之后的工作；4）为脸部生成扰动；5）返回原大小的扰动后的图像</p>
<h1 id="2-一些背景知识"><a href="#2-一些背景知识" class="headerlink" title="2 一些背景知识"></a>2 一些背景知识</h1><h2 id="2-1-损失函数"><a href="#2-1-损失函数" class="headerlink" title="2.1 损失函数"></a>2.1 损失函数</h2><p>关于损失函数，普通的分类一般用 cross-entropy loss，交叉熵损失；训练人脸识别这种模型常用contrastive loss和triplet loss，最近比较新的也有center loss，是把样本归结到最近的质心那一类，还有比如angular-softmax loss，在一个球形内强制实行判别限制？</p>
<h2 id="2-2-攻击算法"><a href="#2-2-攻击算法" class="headerlink" title="2.2 攻击算法"></a>2.2 攻击算法</h2><p>paper中有这么一句：PGD在半径为（艾普斯龙）的球空间内搜寻对抗样本，CW在k（kai）的范围内找到一个最低扰动的对抗样本的最短距离。<br>附一个用pytorch实现的各种攻击算法，备用。<br><a href="https://github.com/Harry24k/adversarial-attacks-pytorch" target="_blank" rel="noopener">https://github.com/Harry24k/adversarial-attacks-pytorch</a></p>
        
          <p class="article-more-link">
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/" data-id="cka6ei4t400004ocp48p63yc0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/hello-world/" class="article-date">
  <time datetime="2020-05-14T06:11:16.196Z" itemprop="datePublished">2020-05-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/hello-world/" data-id="cka6dp0hi0000vwcpgjktdejk" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">图神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 10px;">对抗攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" style="font-size: 15px;">对抗样本生成</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/">论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/">论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/">论文笔记：1   Face-Off：Adversarial Face Obfuscation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Meiyi Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.css">

  
<script src="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.pack.js"></script>




<script src="https://heqi867610481.github.io/KingNothing.github.io/js/script.js"></script>




  </div>
</body>
</html>