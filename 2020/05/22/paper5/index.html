<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks | </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="BGM：Crimson Bow and Arrow – Epica 1 论文总体思路现存的输入不可知的对抗性扰动展示了一种有趣但现在无法解释的视觉模式。本篇论文引入了一种结构化的程序噪声函数来生成通用对抗扰动（UAP）的方法。这种方法在计算机图形化中广泛应用并且被设计为可参数化的。这种方式生成的噪声图样和现存的通用对抗扰动在视觉上有着相似性。此方法揭示了现在流行的DCN架构（比如Inception">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks">
<meta property="og:url" content="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/index.html">
<meta property="og:site_name">
<meta property="og:description" content="BGM：Crimson Bow and Arrow – Epica 1 论文总体思路现存的输入不可知的对抗性扰动展示了一种有趣但现在无法解释的视觉模式。本篇论文引入了一种结构化的程序噪声函数来生成通用对抗扰动（UAP）的方法。这种方法在计算机图形化中广泛应用并且被设计为可参数化的。这种方式生成的噪声图样和现存的通用对抗扰动在视觉上有着相似性。此方法揭示了现在流行的DCN架构（比如Inception">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-05-22T02:37:58.000Z">
<meta property="article:modified_time" content="2020-05-26T11:24:51.241Z">
<meta property="article:author" content="Meiyi Jiang">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="对抗样本生成">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="https://heqi867610481.github.io/KingNothing.github.io/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/">Home</a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://heqi867610481.github.io/KingNothing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-paper5" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/" class="article-date">
  <time datetime="2020-05-22T02:37:58.000Z" itemprop="datePublished">2020-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Crimson Bow and Arrow – Epica</p>
<h1 id="1-论文总体思路"><a href="#1-论文总体思路" class="headerlink" title="1 论文总体思路"></a>1 论文总体思路</h1><p>现存的输入不可知的对抗性扰动展示了一种有趣但现在无法解释的视觉模式。本篇论文引入了一种结构化的程序噪声函数来生成通用对抗扰动（UAP）的方法。这种方法在计算机图形化中广泛应用并且被设计为可参数化的。这种方式生成的噪声图样和现存的通用对抗扰动在视觉上有着相似性。此方法揭示了现在流行的DCN架构（比如Inception v3和YOLO v3）的系统脆弱性。此外，过程中用了贝叶斯优化来有效地学习程序噪音参数来构建低代价无目标的黑盒攻击。进一步的，启发了输入不可知的防御来提高模型对对抗扰动的稳定性。攻击方法的普遍性暗示了DCN可能对低层级类别不可知的特征的聚合很敏感。<br>实验过程，首先在大规模ImageNet classifier上进行黑盒攻击，误分类率高达98.3%。攻击也迁移到了目标检测任务中，结果表示对YOLO v3目标检测器的检测物体有模糊效果。<br>论文创新点：1）第一个对模型不可知黑盒生成通用对抗扰动的方法。2）利用贝叶斯优化来有效加强黑盒攻击。他提高了5折随机参数选择的查询效率，并且效果要好于现在流行的L-BFGS优化算法。3）实验证据表明，程序噪音UAP似乎利用DCN的低层级特征，这一脆弱性可能会被利用创造跨应用的通用对抗性扰动。</p>
<h1 id="2-攻击模型"><a href="#2-攻击模型" class="headerlink" title="2 攻击模型"></a>2 攻击模型</h1><h2 id="2-1-攻击的普遍性（generalizability）"><a href="#2-1-攻击的普遍性（generalizability）" class="headerlink" title="2.1 攻击的普遍性（generalizability）"></a>2.1 攻击的普遍性（generalizability）</h2><p>generalizability衡量了两个方面的事情，一个是可移植性，另一个是universality。Input-specific类型的对抗扰动是针对给定的输入以及模型，是既不transferability，也不universality的。Transferable对抗扰动指，加到同一个输入上，能够使不同的模型误分类，一方面加大了攻击面，另一方面也为黑盒攻击找替代模型奠定基础。Universal的扰动指的是，对于一个数据集的大部分图片，添加上同一个扰动都可以造成误分类。Cross-model universal的扰动就是既transferability又universal。</p>
<h2 id="2-2-攻击类型"><a href="#2-2-攻击类型" class="headerlink" title="2.2 攻击类型"></a>2.2 攻击类型</h2><p>前提是对于躲避攻击，认为攻击者可以对模型进行输入并得到输出。白盒攻击：对模型架构，训练集，参数的全知识。灰盒攻击：攻击者可以构造相似规模的替代模型，并且能够得到相似的数据集（此方法也可用于黑盒设置）。黑盒攻击：攻击者不知道目标模型也无法得到替代数据集，与目标模型唯一的互动是“query”它。由于黑盒攻击依赖于做大量query来获取信息，这就增加了被发现的几率。有一些黑盒攻击方案应用了零阶优化和梯度估计，但是query次数仍然过多。目前查询次数最少的一种方式用了匪帮优化框架，在ImageNet数据集的 每张图片平均约1000次查询。</p>
<h1 id="3-程序噪声"><a href="#3-程序噪声" class="headerlink" title="3 程序噪声"></a>3 程序噪声</h1><p>程序噪声函数是用来生成图片模式的算法，通常用于创建自然细节以增强视频和图形制作中的图像。具有快速，可扩展，低内存占用等特点。<br>现存的通用对抗扰动（UAP），展现出的很有趣的一点是，他们的“通用性”，揭示了更广泛或者与类无关的特征，而机器学习算法又对此很敏感。论文做的假设就是程序噪声既然视觉上和那些UAP很相像，就也能起到UAP的作用。而且程序噪声生成的参数相对较少，可以负担得起黑盒攻击的query。程序噪声可分为3类：lattice gradient noise，sparse convolution noise和explicit noise。<br>lattice gradient noise通过在网格的整数点上随机插值或者梯度生成噪声，Perlin噪声是其代表。Sparse convolution noise随机定位并赋权重的核（指图片卷积用到的矩阵）的综合，Gabor noise是其代表。Explicit noise生成过程中，图片被提前生成并存储，这就需要较大的存储空间，因此在本论文的环境不适用。</p>
<h2 id="3-1-Perlin-Noise"><a href="#3-1-Perlin-Noise" class="headerlink" title="3.1 Perlin Noise"></a>3.1 Perlin Noise</h2><h2 id="3-2-Gabor-Noise"><a href="#3-2-Gabor-Noise" class="headerlink" title="3.2 Gabor Noise"></a>3.2 Gabor Noise</h2><h1 id="4-DCN脆弱性实验"><a href="#4-DCN脆弱性实验" class="headerlink" title="4 DCN脆弱性实验"></a>4 DCN脆弱性实验</h1><p>实验数据集来源是the ILSVRC2012 ImageNet分类任务的验证集。测试的DCN架构是VGG-19，ResNet-50，Inception v3和Inception ResNet v2（IRv2），这些都是在ImageNet上预训练好的。此外还有一个IRv2的改进版本：对基于梯度的对抗攻击更鲁棒的调好参数的IRv2（IRv2ens）网络，它与IRv2同架构但是不同参数。<br>关于扰动参数设置，Perlin的噪声参数有：$\lambda$x，$\lambda$y，$\phi$sine和$\Omega$，Gabor的噪声参数有：$\sigma$，$\lambda$，$\omega$和$\xi$。其中，Perlin的$\lambda$x，$\lambda$y，$\phi$sine和Gabor的$\sigma$，$\lambda$是正值，且由图片的边长d来限定。衡量各向同性的$\xi$取值范围在1到12之间，衡量octaves数量的$\Omega$取值范围为1到4，二者都是离散的。$\omega$数值范围0到2$\pi$。<br>关于衡量指标，定义了通用规避率，模型的平均敏感度以及针对特别输入的规避率。实验设置从图片验证集中随机抽出5000张图片，产生的扰动有1000来自Gabor，1000来自Perlin，还有10000来自随机扰动。对于程序噪声而言，1000次对黑盒的查询就足以得到结果。<br>从对实验结果的分析来看，Perlin总体表现比Gabor要好一点。对于Gabor而言，$\lambda$和通用规避率表现出了高相关，其他参数线性相关程度较低。$\lambda$和规避率的相关性表明低频的Gabor噪声图像意味着高通用规避。对于Perlin而言，规避率和octaves的数量$\Omega$有着中等程度的负相关，和$\phi$sine有着较高的正相关。这说明高频的Perlin噪声图样有着更高的规避率，然后具有较少细节和曲率的图样可能也能取得较高的规避率。IRv2ens的表现似乎都是都低频噪声图样更敏感，这可能是因为模型被训练的可以抵抗基于梯度的攻击，可能更多地是高频的扰动。但对其他的模型，Gabor和Perlin的噪声频率表现出了和规避率相反的相关，这种差异可能说明了这些噪声图样有不同的特征。<br>对于模型的敏感度而言，可以观察到对于每个模型，容易受两种噪声图样影响的都是相似的一群输入，模型也是对几乎同一批输入的程序噪声更敏感。<br>Perlin的对分类的影响较Gabor而言更有定向性，这可能是因为Perlin噪声对于特定的类具有更大的偏差，但是Gabor更无差别。<br>其他的一些讨论：1）似乎DCN的分类结果更依赖于质地（texture）而不是形状，好像对质地更有偏差。2）大多数有着高规避率的扰动没有对某一类的偏向，这可能暗示了UAP利用了更低层级的特征。程序噪声产生的视觉效果上最相近的是Singular Vector Attack（文献30），而SVA针对的是网络的浅层来生成对抗噪声。而且在自然图片上训练的DCN学习到的卷积filter视觉上也与Gabor核和色斑很相似（文献48，76）。Gabor噪声看起来 像是浅层特征的简单集合，而Perlin噪声似乎是浅层特征的更复杂的混合。这可能解释了为什么Perlin噪声的攻击比Gabor效果好。3）程序噪声在各个模型之间的迁移性比较好可能是因为他们有着同样的训练集，学习算法（反向传播），架构中的相同组件（卷积层）。这暗示了这些模型共有一些输入不可知的脆弱性。4）迁移学习的广泛应用可能有些安全隐患，因为训练过程中最前几层的参数被固定，保留了低层次的特征。准确衡量迁移学习后的模型对相同攻击的脆弱性的程度是未来的一个研究方向。5）本论文研究内容和和其他的对抗样本生成方式不同，其他的比如贝叶斯网络，GAN，可变自动编码器（VAE）等，都需要额外的训练模型或网络。而且本论文中的方法参数搜索维度较小，只有4个，而其他的方法是整个图片的整个输入空间。当然代价是这种方法没有捕捉到这个范围之外的对抗扰动。6）其他的一个缺点是衡量扰动公式中用到了l无穷范式，lp范式的一个缺点就是同样的lp范式似乎对高频的pattern更视觉可见。频率可以被用作一个额外的限制，并且发展一个人类直觉的更好表达来代替lp范式，这也是未来的研究方向。</p>
<h1 id="5-黑盒攻击的优化和比较"><a href="#5-黑盒攻击的优化和比较" class="headerlink" title="5 黑盒攻击的优化和比较"></a>5 黑盒攻击的优化和比较</h1><p>对于针对专门输入的和通用的分类器，比较了几种黑盒优化技巧，最终证明贝叶斯优化对于参数的确定是一种很有效的方式。</p>
<h2 id="5-1-贝叶斯优化"><a href="#5-1-贝叶斯优化" class="headerlink" title="5.1 贝叶斯优化"></a>5.1 贝叶斯优化</h2><p>贝叶斯优化是一种序列优化算法用来给黑盒目标函数寻找优化参数。贝叶斯优化法由一个概率替代模型和一个指引查询的获得函数组成。概率替代模型通常是一个高斯过程，获得函数通常用高斯回归，通常在每次查询后更新关于目标函数参数的置信。</p>
<h3 id="5-1-1-高斯过程"><a href="#5-1-1-高斯过程" class="headerlink" title="5.1.1 高斯过程"></a>5.1.1 高斯过程</h3><h3 id="5-1-2-获得函数"><a href="#5-1-2-获得函数" class="headerlink" title="5.1.2 获得函数"></a>5.1.2 获得函数</h3><h2 id="5-2-实验设置"><a href="#5-2-实验设置" class="headerlink" title="5.2 实验设置"></a>5.2 实验设置</h2><p>使用Inception v3模型，训练集和验证集都来源于ILSVRC2012。实验将贝叶斯优化和L-BFGS算法相比较，L-BFGS是一种常应用于黑盒算法和机器学习的拟牛顿优化算法。由于程序噪声函数是不可微分的，采用有限差分近似来估计梯度。这种梯度近似和用在其他黑盒攻击（比如零阶攻击）上的优化算法很像，但是被应用在一个更小的搜索空间内。当L-BFGS收敛，很可能是找到了一个局部最优解，这时就用一个不同的随机初始值来重新开始优化，当达到查询次数限制时停止，选择找到的最优值。实际实验的时候，这个查询限制设置为1000，但往往收敛速度都很快，不用1000次查询。</p>
<h2 id="5-3-针对特定输入的黑盒攻击"><a href="#5-3-针对特定输入的黑盒攻击" class="headerlink" title="5.3 针对特定输入的黑盒攻击"></a>5.3 针对特定输入的黑盒攻击</h2><p>这个实验针对模型原来能正确分类的图片中的一个子集，希望可以最大化子集的规避率，衡量指标有成功率和平均查询次数。在这个实验中，允许攻击者得到模型的输出概率向量，并使用松散GP来更好的对贝叶斯优化进行缩放，因为标准的GP是是对观察次数按立方缩放。实验结果来看，贝叶斯优化法的结果很优秀，平均7次查询就能达到91.6%的成功率，L-BFGS表现很差，他会陷在局部最优之中浪费掉很多查询机会，需要在不同的初始点重启多次。</p>
<h2 id="5-4-和Ilyas等人成果的比较"><a href="#5-4-和Ilyas等人成果的比较" class="headerlink" title="5.4 和Ilyas等人成果的比较"></a>5.4 和Ilyas等人成果的比较</h2><p>Ilyas等人的做法是把攻击描述成一个梯度估计的问题（就像基于梯度的白盒攻击），然后用一个匪帮优化的框架来解决。比较结果是当限制查询次数在千以内的话，程序噪声攻击很明显的优于他们的做法。大多数的方法是在图片所有维度进行搜索，几乎在足够的查询下是一定可以找到对抗样本的。bandit方法为了减少查询次数，对成功率有所牺牲，而程序噪声方法做的程度更深。当然程序噪声的做法也可以通过引入更多参数（比如使用不同的颜色图），来扩大搜索空间，但是这可能破坏它天然的高通用规避率。</p>
<h1 id="6-程序噪声攻击YOLO-v3"><a href="#6-程序噪声攻击YOLO-v3" class="headerlink" title="6 程序噪声攻击YOLO v3"></a>6 程序噪声攻击YOLO v3</h1><p>目标检测模型YOLO v3属于SSD，意味着对输入图片一遍就得到预测结果，而比如FastR-CNN或FasterR-CNN，他们是基于region proposals的，处理速度并不如SSD类型的。数据集使用MS COCO数据集。这部分实验没有进一步应用优化算法，而是和4部分的实验比较相像。实验结果表明攻击的高成功率更有可能是由模型对扰动的敏感性引起的，而不是对质地的偏差。</p>
<h1 id="7-未来方向总结"><a href="#7-未来方向总结" class="headerlink" title="7 未来方向总结"></a>7 未来方向总结</h1><p>1）对于其他应用（语音识别，NLP，强化学习）寻找程序噪声的类似物。作为开始，可以通过寻找使隐藏层差别最大化的扰动开始，比如通过Singular Vector Attack或者对DCN的浅层特征视觉化来推断模型学到的浅层特征。<br>2）可以最小化小扰动的影响的输入不可知的防御可能在降低模型的敏感度上很有效，而不用专门针对各种攻击来训练。比如论文最后尝试了一下降噪这个手段。用特别的过滤器来降噪是信号处理的一个通常的预处理手段。比如中值滤波。中值滤波是一种平滑操作，将每个输入的值代替为他邻居们的值的中位数，通常既保留了边，也移除了噪声。这种做法平滑了高频噪声，而高频噪声又和Perlin噪声的规避率有很高相关。论文做了实验，在Inception v3模型前加了中值滤波过滤器的预处理步骤。实验结果规避率有所下降，尽管没有下降很多。未来的工作希望可以尝试别的降噪算法，比如模型压缩，Jacobian正则化等。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/" data-id="ckanu4eaq0000skcp11eldwxc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">图神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 10px;">对抗攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" style="font-size: 15px;">对抗样本生成</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/">论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/">论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/">论文笔记：1   Face-Off：Adversarial Face Obfuscation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Meiyi Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.css">

  
<script src="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.pack.js"></script>




<script src="https://heqi867610481.github.io/KingNothing.github.io/js/script.js"></script>




  </div>
</body>
</html>