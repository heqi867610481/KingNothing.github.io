<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：1   Face-Off：Adversarial Face Obfuscation | </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="BGM：Dies Irae – Dark Moor（配合食用更佳）（没什么比output同时夹带私货更开心了） 1 论文总体思路首先这篇设计的Face-Off针对的是人脸recognition而不是detection。目标是使服务提供者仍然能检测到人脸，但是却把他认错。面临的挑战有 1）现存的对抗攻击多关注于分类器（直接输出分类结果），但是paper解决的问题是针对所谓“metric learni">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：1   Face-Off：Adversarial Face Obfuscation">
<meta property="og:url" content="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/index.html">
<meta property="og:site_name">
<meta property="og:description" content="BGM：Dies Irae – Dark Moor（配合食用更佳）（没什么比output同时夹带私货更开心了） 1 论文总体思路首先这篇设计的Face-Off针对的是人脸recognition而不是detection。目标是使服务提供者仍然能检测到人脸，但是却把他认错。面临的挑战有 1）现存的对抗攻击多关注于分类器（直接输出分类结果），但是paper解决的问题是针对所谓“metric learni">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/14/paper1/images/1.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200514114354350.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200514115049342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0p1Z2dsZV9Bem90aA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200514112320278.png">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/14/paper1/images/2.png">
<meta property="article:published_time" content="2020-05-14T06:37:01.000Z">
<meta property="article:modified_time" content="2020-05-15T02:42:00.855Z">
<meta property="article:author" content="Meiyi Jiang">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="对抗样本生成">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/14/paper1/images/1.png">
  
    <link rel="alternate" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="https://heqi867610481.github.io/KingNothing.github.io/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/">Home</a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://heqi867610481.github.io/KingNothing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-paper1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/" class="article-date">
  <time datetime="2020-05-14T06:37:01.000Z" itemprop="datePublished">2020-05-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      论文笔记：1   Face-Off：Adversarial Face Obfuscation
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：Dies Irae – Dark Moor（配合食用更佳）（没什么比output同时夹带私货更开心了）</p>
<h1 id="1-论文总体思路"><a href="#1-论文总体思路" class="headerlink" title="1 论文总体思路"></a>1 论文总体思路</h1><p>首先这篇设计的Face-Off针对的是人脸recognition而不是detection。目标是使服务提供者仍然能检测到人脸，但是却把他认错。<br>面临的挑战有 1）现存的对抗攻击多关注于分类器（直接输出分类结果），但是paper解决的问题是针对所谓“metric learning system”，这种人脸识别/验证都是把输入用特征向量表示，然后去找最近的一簇。2）paper面临的是要实现黑盒攻击，而且也不能利用黑盒的输出去生成对抗性样本。<br>对于困难1），解决办法是专门为“metric learning system”设计了两种损失函数。损失函数目的是在得到嵌入向量时就尽量让图片远离正确答案。<br>对于困难2），解决办法是利用移植的办法。先用一个替代模型（白盒）生成对抗样本，然后用一个因子阿尔法a放大扰动。用放大因子也有个好处就是减少了生成对抗样本的时间。<br>这个替代的白盒模型用了两种模型【25】【36】。生成对抗样本的攻击算法也用了两种，即CW和PGD。<br>然后Face-Off的工作流程是这样的：1）收到用户的目标图片；2）识别并分离出脸部；3）调整大小为之后的工作；4）为脸部生成扰动；5）返回原大小的扰动后的图像</p>
<h1 id="2-一些背景知识"><a href="#2-一些背景知识" class="headerlink" title="2 一些背景知识"></a>2 一些背景知识</h1><h2 id="2-1-损失函数"><a href="#2-1-损失函数" class="headerlink" title="2.1 损失函数"></a>2.1 损失函数</h2><p>关于损失函数，普通的分类一般用 cross-entropy loss，交叉熵损失；训练人脸识别这种模型常用contrastive loss和triplet loss，最近比较新的也有center loss，是把样本归结到最近的质心那一类，还有比如angular-softmax loss，在一个球形内强制实行判别限制？</p>
<h2 id="2-2-攻击算法"><a href="#2-2-攻击算法" class="headerlink" title="2.2 攻击算法"></a>2.2 攻击算法</h2><p>paper中有这么一句：PGD在半径为（艾普斯龙）的球空间内搜寻对抗样本，CW在k（kai）的范围内找到一个最低扰动的对抗样本的最短距离。<br>附一个用pytorch实现的各种攻击算法，备用。<br><a href="https://github.com/Harry24k/adversarial-attacks-pytorch" target="_blank" rel="noopener">https://github.com/Harry24k/adversarial-attacks-pytorch</a></p>
<a id="more"></a>
<h3 id="2-2-1-CW"><a href="#2-2-1-CW" class="headerlink" title="2.2.1 CW"></a>2.2.1 CW</h3><p>关于生成对抗样本，确定扰动德尔塔的问题一般表示为一个有限制的优化问题。具体表示如下图。然后算法paper用的就是CW和PGD了。<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/14/paper1/images/1.png" alt="生成对抗样本的问题"><br>先码一下CW原论文地址：<a href="https://arxiv.org/pdf/1608.04644.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.04644.pdf</a><br>此处参考了博客 <a href="https://www.cnblogs.com/tangweijqxx/p/10627360.html" target="_blank" rel="noopener">https://www.cnblogs.com/tangweijqxx/p/10627360.html</a><br>和<a href="http://shaobaobaoer.cn/archives/749/carliniattack" target="_blank" rel="noopener">http://shaobaobaoer.cn/archives/749/carliniattack</a><br>CW是一种很强攻击能力的白盒攻击算法，是一种基于优化的对抗样本生成算法。（基于梯度的攻击算法有deepfool，FGSM）<br>核心思想如下：将对抗样本作为变量。攻击考虑两方面。一是对抗样本和原样本差距尽量小；另一个是对抗样本使得模型分类错误，而且模型分错的那类的概率还得尽量高。总体而言，优化函数可定义如下：<br><img src="https://img-blog.csdnimg.cn/20200514114354350.png" alt="优化函数定义"><br>然后具体的目标函数选择有很多，如下。其中f6表现最好。这个表现由两个因素衡量，一个是扰动的平均大小，一个是攻击成功率。<br><img src="https://img-blog.csdnimg.cn/20200514115049342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0p1Z2dsZV9Bem90aA==,size_16,color_FFFFFF,t_70" alt="目标函数选择"><br>下图是CW攻击里比较常见的一种。w是对抗样本，t是攻击标签，公式中r_n就衡量了对抗样本和原始样本的差距。tanh函数此处的作用是将函数值扩展到负无穷到正无穷。<br>目标函数的定义类似于f6。公式中Z(x)表示样本x输入到模型还没经过softmax那一步时的输出向量，Z(x)右下角的脚标i或者t表示这个向量对应i类别或者t类别的那一个输出值。k代表置信度，k越大模型分错且错成那一类的概率越大，但对抗样本也更难找了。一般取40最佳。<img src="https://img-blog.csdnimg.cn/20200514112320278.png" alt="CW攻击算法核心公式"><br>实际编程实现的话，据说IBM的ART工具很强。</p>
<h3 id="2-2-2-PGD"><a href="#2-2-2-PGD" class="headerlink" title="2.2.2 PGD"></a>2.2.2 PGD</h3><h2 id="2-3-LIPSCHITZ连续性"><a href="#2-3-LIPSCHITZ连续性" class="headerlink" title="2.3 LIPSCHITZ连续性"></a>2.3 LIPSCHITZ连续性</h2><p>数学上的定义指的是一段区间内的斜率上限。paper中提到希望找一个子区间，在这个子区间内，这个斜率上限很高。这样的话图片的一个小变化就能使得embedding的扰动很大。paper做了一些实验来证明对抗样本附近区间具有强LIPSCHITZ连续性。实验包含很多对比内容，包括center和triplet两种人脸识别的方式，还用了不同的分类器，还分别用了CW和PGD两种攻击算法。paper想证明的是这样的话乘一个小因子就对扰动后的图片的embedding影响很大，所以小因子很有用。</p>
<h2 id="2-4-提到的数据集"><a href="#2-4-提到的数据集" class="headerlink" title="2.4 提到的数据集"></a>2.4 提到的数据集</h2><p>MNIST<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a>。MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST). 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据。可以不用下载，在keras.datasets包中直接调用。</p>
<pre><code class="bash">from keras.datasets import mnist</code></pre>
<p>CIFAR-10是一个包含60000张图片的数据集。其中每张照片为32*32的彩色照片，每个像素点包括RGB三个数值，数值范围 0 ~ 255。所有照片分属10个不同的类别，分别是 ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’<br>其中，5万张作为训练集，1万张作为测试机。训练集被分为了5批训练和1批测试。每一批都是1万张。测试集是从每一种分类中随机抽取出来1000张组成。训练集从10个分类中各自随机抽取5000张，一共5万张。下载：<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">http://www.cs.toronto.edu/~kriz/cifar.html</a></p>
<h2 id="2-5-双线性内插法"><a href="#2-5-双线性内插法" class="headerlink" title="2.5 双线性内插法"></a>2.5 双线性内插法</h2><p>用于图像缩放（OpenCV可以实现？）</p>
<h1 id="3-系统设计"><a href="#3-系统设计" class="headerlink" title="3 系统设计"></a>3 系统设计</h1><p>也就是说对于每一次任务，都是训练两个网络，一个是用于生成对抗样本的替代白盒（接受的输入是裁剪后的小图片），另一个是测试放大扰动后的对抗样本的黑盒模型。</p>
<h2 id="3-1-替代白盒攻击部分"><a href="#3-1-替代白盒攻击部分" class="headerlink" title="3.1 替代白盒攻击部分"></a>3.1 替代白盒攻击部分</h2><p><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/14/paper1/images/2.png" alt="设计的优化函数"><br>优化函数和CW很像。但是其中的L损失函数是由两部分构成的。1）目标损失函数，衡量了对抗样本和target标签（target指的是不是正确分类的某个类）的一系列脸的距离；2）hinge损失函数，希望对抗样本和原始样本之前的距离比对抗样本和target样本距离大，大多少由公式中的k决定。</p>
<h2 id="3-2-黑盒攻击部份"><a href="#3-2-黑盒攻击部份" class="headerlink" title="3.2 黑盒攻击部份"></a>3.2 黑盒攻击部份</h2><p>乘一个小因子不影响人眼的鉴别力，但是却可以提升模型间的可移植性。可用来加强对抗样本。在返回给用户之前，扰动后的图片还被resize回原来的大小。</p>
<h1 id="4-参数选择相关实验"><a href="#4-参数选择相关实验" class="headerlink" title="4 参数选择相关实验"></a>4 参数选择相关实验</h1><p>paper在这两个数据集上做了实验。MNIST的白盒用的是6层CNN（输入20x20），黑盒用的是CNN（输入28x28）；CIFAR-10的白盒用的是6层CNN（输入20x20），黑盒用的是VGG-based（输入32x32）。对于数据集中的每个元素，都用两种攻击算法生成了对应的扰动版本。<br>CW（k，kai）和PGD（艾普斯龙）各有一个参数。还有一个放大因子（阿尔法），还变化迭代次数。结论有：1）迭代次数多的话，移植性会更好，但是代价就是时间长。2）对两种攻击而言，放大都提高了移植性。3）CW能用较小的放大取得和PGD同等的移植性。4）扰动经得起resize。5）低的margin值，使结果相交更快但是可移植性变差。</p>
<h1 id="5-实验和评估"><a href="#5-实验和评估" class="headerlink" title="5 实验和评估"></a>5 实验和评估</h1><p> 两种攻击算法(CW, PGD), 两种图片识别模型(center, triplet), 两种损失函数(target, hinge)。接下来就看什么组合效果最好。 最后Azure Face API, Amazon Rekognition, 和Face++ Cognitive Services三位幸运的小朋友被抓来做最后的效果评估。<br> 在第一步把人脸裁出来的时候用了MTCNN来detect人脸。<br> 然后脸图对于Facenet（triplet）和center loss两种模型分别搞成96x96和112x96的<br> 白盒这边paper好像用了个现成的开源model（Facenet）来得到图片的embedding。（<a href="https://github.com/davidsandberg/facenet" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet</a>）而且Facenet用的是triplet，生成128维embedding，还似乎被集成到了Kares里？center模型里把全连接层的512维输出当embedding。<br> 然后用那三个API测试，每次都是传两张图片，API返回一个置信值。只不过具体三个还有区别。每个对抗样本和5个同一个人的图片对比，最终取平均作为置信结果。<br> 结论是，center模型和hinge损失结合是最棒哒！<br> 评估的时候都是纵轴是可移植性（用黑盒的匹配置信数值表示），横轴是l2范式表示的扰动（乘了因子后的）。还分别对剪裁后的和resize后的做了实验。<br> paper发现对于CW而言，阿尔法的选择比参数k（kai）影响更大，k（kai）作用很小。对于PGD而言，艾普斯龙对可移植性影响更大，值越大更快地实现可移植性。PGD生成的样本扰动比CW更高。<br> BTW，对于图像paper研究了两类，一个是肖像，一个是background。关于两类的扰动可接受度，是人工调查来确定的。（相关内容竟占了宝贵的两页！）</p>
<h1 id="4-相关引用论文"><a href="#4-相关引用论文" class="headerlink" title="4 相关引用论文"></a>4 相关引用论文</h1><h2 id="4-1-黑盒相关"><a href="#4-1-黑盒相关" class="headerlink" title="4.1 黑盒相关"></a>4.1 黑盒相关</h2><p>人们处理黑盒问题，一个常见地思路就是训练相似的网络，利用目标黑盒模型的label oracle，生成对抗模型然后移植。但另一条思路在生成对抗样本的时候没有利用黑盒。<br>这里提到了两篇论文。回头看一下。<br><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Moosavi-Dezfooli_Universal_Adversarial_Perturbations_CVPR_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/papers/Moosavi-Dezfooli_Universal_Adversarial_Perturbations_CVPR_2017_paper.pdf</a><br><a href="https://arxiv.org/pdf/1704.03453.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.03453.pdf</a></p>
<h2 id="4-2-其他"><a href="#4-2-其他" class="headerlink" title="4.2 其他"></a>4.2 其他</h2><p>还有一篇引用论文有点感兴趣，针对的是标准的图片分类器，设计了攻防的博弈。同时优化了隐私方面和可用性方面。<br><a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w16/papers/Cox_Protecting_Visual_Secrets_CVPR_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017_workshops/w16/papers/Cox_Protecting_Visual_Secrets_CVPR_2017_paper.pdf</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/" data-id="cka6ei4t400004ocp48p63yc0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection
        
      </div>
    </a>
  
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">图神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 10px;">对抗攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" style="font-size: 15px;">对抗样本生成</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/22/paper5/">论文笔记：5   Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/">论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/">论文笔记：1   Face-Off：Adversarial Face Obfuscation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Meiyi Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.css">

  
<script src="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.pack.js"></script>




<script src="https://heqi867610481.github.io/KingNothing.github.io/js/script.js"></script>




  </div>
</body>
</html>