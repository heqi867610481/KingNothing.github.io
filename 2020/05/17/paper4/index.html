<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure | </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="BGM：King Nothing – Metallica （今天没打鼓，良心痛。看一篇不太了解的领域的论文，换下口味。） 1 背景知识这篇论文是关于对基于图的分类的攻击的（好绕）。基于图的分类大致可分为这两种：Collective Classification和图神经网络（GNN）。然后这篇论文是针对Collective Classification这一类的。论文中说现在对抗攻击大多都是针对非图的">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure">
<meta property="og:url" content="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/index.html">
<meta property="og:site_name">
<meta property="og:description" content="BGM：King Nothing – Metallica （今天没打鼓，良心痛。看一篇不太了解的领域的论文，换下口味。） 1 背景知识这篇论文是关于对基于图的分类的攻击的（好绕）。基于图的分类大致可分为这两种：Collective Classification和图神经网络（GNN）。然后这篇论文是针对Collective Classification这一类的。论文中说现在对抗攻击大多都是针对非图的">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/4.png">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/5.png">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/6.png">
<meta property="article:published_time" content="2020-05-17T11:47:27.000Z">
<meta property="article:modified_time" content="2020-05-19T14:34:08.353Z">
<meta property="article:author" content="Meiyi Jiang">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="对抗攻击">
<meta property="article:tag" content="图神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/4.png">
  
    <link rel="alternate" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="https://heqi867610481.github.io/KingNothing.github.io/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/">Home</a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://heqi867610481.github.io/KingNothing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-paper4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/" class="article-date">
  <time datetime="2020-05-17T11:47:27.000Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>BGM：King Nothing – Metallica （今天没打鼓，良心痛。看一篇不太了解的领域的论文，换下口味。）</p>
<h1 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h1><p>这篇论文是关于对基于图的分类的攻击的（好绕）。基于图的分类大致可分为这两种：Collective Classification和图神经网络（GNN）。然后这篇论文是针对Collective Classification这一类的。论文中说现在对抗攻击大多都是针对非图的算法，就算是针对图的，也是GNN比较多。对于某些特定的安全问题，Collective Classification效果要好一点 。在这里把论文提到的基于图分类的相关算法都列出学习一下。<br>先说一下数据的结构。给定的是一个图和训练集。图可以是有向图或者无向图。训练集是图上一部分标记为正节点和负节点的节点。基于图的分类就是要预测这些没标记的节点是正是负。</p>
<h2 id="1-1-Collective-Classification"><a href="#1-1-Collective-Classification" class="headerlink" title="1.1 Collective Classification"></a>1.1 Collective Classification</h2><p>Collective Classification基于训练集给每个点定义了一个前声誉得分（prior reputation score），接着给每条边分配或学习权重，然后然后在这个有权重的图里传播前声誉得分，来获得每个节点的后声誉得分（posterior）。后声誉得分被用来给没标签的节点分类。不同的CC方法用不同的方式定义前声誉得分，分配/学习边权重，以及传播前声誉得分。<br>常见的有这么几种：基于RW的，基于LBP的，基于LinLBP的，以及JWP方法。</p>
<h3 id="1-1-1-基于RW的方法"><a href="#1-1-1-基于RW的方法" class="headerlink" title="1.1.1 基于RW的方法"></a>1.1.1 基于RW的方法</h3><p>首先关于前声誉得分，给标记为正节点的赋值为1，标记为负节点的赋值为0，还没标记的节点赋值为0.5。此外关于边的权重，赋值为同样的值或者赋值为用节点属性学习到的权重。最后，利用random walk在有权重的图中传播声誉得分。他们迭代的把一个节点的当前名誉得分，根据边的权重，按比例传播给邻居节点。然后节点的新的名誉得分，是邻居们的名誉得分总和。</p>
<a id="more"></a>
<h3 id="1-1-2-基于LBP的方法"><a href="#1-1-2-基于LBP的方法" class="headerlink" title="1.1.2 基于LBP的方法"></a>1.1.2 基于LBP的方法</h3><p>一般先给所有边赋相同的权重值。然后把图看作成对的马尔科夫随机场模型，然后利用LBP（Loopy Belief Propagation ）实现传播来获得后声誉得分。但是这一方法有两个众所周知的弊端：对于循环图不保证能收敛，以及不能缩放（因为包含每条边的信息）。LinLBP就是通过线性化了LBP来解决了这两个问题。</p>
<h3 id="1-1-3-基于LinLBP的方法"><a href="#1-1-3-基于LinLBP的方法" class="headerlink" title="1.1.3 基于LinLBP的方法"></a>1.1.3 基于LinLBP的方法</h3><h3 id="1-1-4-JWP方法"><a href="#1-1-4-JWP方法" class="headerlink" title="1.1.4 JWP方法"></a>1.1.4 JWP方法</h3><p>JWP学习边的权重和传播声誉得分同时进行。给出当前的前声誉得分，JWP学习边权重使得1）下一次迭代中标记为正的节点后声誉得分大，而标记为负的节点后声誉得分小。2）如果一个边的两个顶点用当前的后声誉得分被预测有相同的标签，那么这条边就有较大的权重，反之则相反。有了学习到的边的权重，JWP就计算下一次迭代的后声誉得分，这个过程可以用基于LinLBP的传播。但是直接攻击JWP不太好攻击，因为边权重是学习到的。对图做增删操作的影响取决于JWP重新学习后的边权重。但是攻击LinLBP后可以移植到JWP上。</p>
<h2 id="1-2-GNN"><a href="#1-2-GNN" class="headerlink" title="1.2 GNN"></a>1.2 GNN</h2><p>GNN则思路不同。GNN是给图数据生成神经网络，用各种方法学习基于图结构的特征向量，然后用特征向量来分类。细分又可以再分为两类。<br>一类是学习节点特征和分类同时进行，隐藏层的神经元代表节点的特征向量，而特征向量被用来在神经网络的最后一层去分类节点。神经网络的结构由图结构决定，比如代表一个特定节点的某一层的神经元和上一层的代表邻居节点的神经元相连。换句话说，神经网络迭代的计算一个节点的特征向量，通过聚合其邻居节点的特征向量。神经网络参数的学习通过最小化基于图的损失函数（包括训练集内有标签的和仍未有标签的）。如果有着相同的标签的特征向量距离近而不同标签的特征向量距离远的话，基于图的损失函数就小。GCN属于这一类。<br>另一类是先用无监督的学习方法学习节点的特征向量（这一过程也叫graph embedding），然后用特征向量和训练数据集训练一个标准的二分类分类器。然后用分类器预测没标签的节点。DeepWalk和LINE属于这一类。</p>
<h3 id="1-2-1-GCN"><a href="#1-2-1-GCN" class="headerlink" title="1.2.1 GCN"></a>1.2.1 GCN</h3><p>GCN利用神经网络中的光谱图卷积（spectral graph convolution）来学习特征向量，在最后一层应用逻辑回归。</p>
<h3 id="1-2-2-DeepWalk"><a href="#1-2-2-DeepWalk" class="headerlink" title="1.2.2 DeepWalk"></a>1.2.2 DeepWalk</h3><p>总体而言，DeepWalk通过NLP领域的word to vector技术来处理图数据。一个节点可以类比自然语言的一个单词，用精减的random walk来生成节点序列，然后利用skip-gram模型来学习每个节点的特征向量。</p>
<h3 id="1-2-3-LINE"><a href="#1-2-3-LINE" class="headerlink" title="1.2.3 LINE"></a>1.2.3 LINE</h3><p>LINE通过一阶和二阶近似来学习节点的特征向量。一阶近似捕捉图中的边，如果两个节点没有相连，那么一阶近似就是0。两个节点间的二阶近似捕捉他们邻居间的相似性。</p>
<h2 id="1-3-基于图的攻击"><a href="#1-3-基于图的攻击" class="headerlink" title="1.3 基于图的攻击"></a>1.3 基于图的攻击</h2><p>目前看有两类吧。一类是攻击者操纵添加固定数量的正或负节点。另一类就是像paper一样的操纵图结构（增删边）。前者提到两个相关论文Chen et al. 提出针对基于图的聚类的攻击。Torkamani and Lowd提出针对基于马尔可夫网络分类器的攻击。<br>后者比如Nettack，针对的是GCN。首先Nettack定义了一个保留扰动的图结构有一些限制，要求攻击前后，图的节点度分布应该是相似的。然后Nettack学习了一个GCN的替代线性模型。最后在前面提到的图结构的限制下，通过最大化替代损失函数来生成假边或者删除边。</p>
<h1 id="2-论文概述"><a href="#2-论文概述" class="headerlink" title="2 论文概述"></a>2 论文概述</h1><p>攻击模型里，认为攻击者是通过操纵图的结构来规避检测的，攻击者生成假边和已删除的边来实现攻击。把攻击设计成一个基于图的最优化问题，但事实上这个问题比较难解。解决方法是提出了几种近似解法方案。最后实现了攻击并在4个图数据集上将其与现有的其他攻击作比较。<br>论文的攻击针对的是采用LinLBP方法的CC模型。针对LinLBP的原因是：LinLBP比较前沿，分类效果比其他的要好；LinLBP一开始对所有边使用同等权重，使得优化问题比较好解。但是，实验证明基于LinLBP的攻击也可以移植到其他CC甚至GNN模型上去。<br>攻击模型中认为攻击者有三个维度的知识：参数，训练集和图。参数比如LinLBP使用的前声誉得分和边的权重。<br>攻击者拥有的恶意节点是正节点，他希望分类器将其认为是负节点，也就是说攻击者希望提升分类的的False Negative率。攻击者增删边的代价是不同的，比如在两个正节点之间插入边比在两个负节点之间插入边代价更小。因此攻击者的攻击目标就是让他的恶意节点们（正节点）获得高的FNR，与此同时有一个最小的增删边的代价。这样的话，这个优化问题的目标函数是改变图架构的总代价，而限制是攻击者选择的正节点们的FNR=1。这就是前文提到的比较难解的问题。原因一个是限制函数很不线性；另一个是优化问题不连续，是个两元优化问题（或增或删边）。论文提出几种途径来近似解决这个问题。比如放开两元取值，变成连续的，解决完优化问题再转化为两元取值。还有就是用后声誉得分代替限制里的FNR，把FNR=1通过拉格朗日因子转化成目标函数。<br>关于实验，首先他们在三个现实世界的用合成的恶意节点，以及一个现实世界的大规模推特图上用真实的恶意节点对攻击做了评估。评估结果是相当有效的，即使攻击者的知识不那么充分（参数和数据集都可以用替代品，图知道20%左右就够用了）。其次，攻击可以移植到其他CC和GNN模型上。第三，和最近的一个攻击Nettack（基于图卷积网络GCN生成假边和删除边）作了比较。</p>
<h1 id="3-攻击模型和优化问题模型"><a href="#3-攻击模型和优化问题模型" class="headerlink" title="3 攻击模型和优化问题模型"></a>3 攻击模型和优化问题模型</h1><h2 id="3-1-攻击模型"><a href="#3-1-攻击模型" class="headerlink" title="3.1 攻击模型"></a>3.1 攻击模型</h2><p>攻击者的背景知识包括（参数，训练集，图）三部分，可以用一个三元组来表示，其中参数和训练集的取值是Y/N，图的取值是部分/全部。<br>还有考虑攻击者能做的事情，他能增删边，但是代价不同。同时考虑到实际生活中一个节点的好友数是有上限的，因此用一个参数K，来表示一个节点能增/删的边的最大数量。</p>
<h2 id="3-2-全知识下的优化问题模型"><a href="#3-2-全知识下的优化问题模型" class="headerlink" title="3.2 全知识下的优化问题模型"></a>3.2 全知识下的优化问题模型</h2><p>LinLBP对于前声誉得分的赋值是这样进行的。如果节点是正节点，则赋值为$\theta$；如果节点是负节点，就赋值为-$\theta$；其他赋值为0。其中$\theta$取值范围是0到1。LinLBP给所有的边赋了相同的权重，这个值的取值范围在0到0.5。<br>图用G=（V,E）表示。A表示邻接矩阵，W表示边的权重矩阵。</p>
<h3 id="3-2-1-最初的优化问题和解决概述"><a href="#3-2-1-最初的优化问题和解决概述" class="headerlink" title="3.2.1 最初的优化问题和解决概述"></a>3.2.1 最初的优化问题和解决概述</h3><p>目标函数是最小化操作图的总代价。限制是1）对于攻击者的目标节点FNR=1；2）每个节点增/删边的数量不大于K。<br>为了使问题好解决一些，对最原始的目标函数做了如下的改动：1）原来的解的取值是由0或1组成的矩阵，现在先放开为连续取值，最后再转化成0或1；2）把优化问题的解减少到只考虑与在攻击者控制之下的target节点相连的边；3）把FNR=1的限制变成关于攻击者目标节点的后声誉得分的限制，然后把限制用拉格朗日因子加到目标函数上去；4）迭代的计算后声誉得分，用中间步骤的后声誉得分来计算优化问题中的连续变量。</p>
<h3 id="3-2-2-公式表达"><a href="#3-2-2-公式表达" class="headerlink" title="3.2.2 公式表达"></a>3.2.2 公式表达</h3><p>一个二值变量矩阵称作攻击矩阵B，Buv来表示节点u到节点v之间的连线状态是否改变（增/删）。连续变量矩阵Cuv表示节点u到节点v之间的连线状态改变的代价（按理说这个代价增或删可以不一样，但这里为了简化就一样了）。因此最初的优化问题的公式表达如下图。（u小于v是为了不重复计算。）<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/4.png" alt="最初的优化公式"><br>上文提到的改动1）2）3）在公式上的体现如下。其中$\lambda$就是拉格朗日因子。Buv这里表示连续取值的，上面有一横表示二值取值的。因为如果后声誉得分为负的话，节点会被预测为负，所以FNR=1的限制就变成了对于$\Tau$中的每一个节点u，都有pu小于0.<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/5.png" alt="改进的优化公式"><br>对于上文提到的改动4）设计每次迭代都包括两个步骤，如下图。其中bu、cu都是行向量。需要注意的是，cuv和Cuv的关系，公式13作为公式8的改写，在u属于$\Tau$而v不属于$\Tau$的时候没有问题，而在u和v都属于$\Tau$的时候，因为公式13没有表面上限制不重复计算，因此他是重复计算了的，所以u和v都属于$\Tau$时，cuv=0.5*Cuv。<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/05/17/paper4/images/6.png" alt="最初的优化公式"><br>解决公式13这个优化问题，采用的是PGD（projected gradient descent）。具体的公式比较复杂，可参考论文第6页，这里就不写了。</p>
<h1 id="4-实验设置和评估"><a href="#4-实验设置和评估" class="headerlink" title="4 实验设置和评估"></a>4 实验设置和评估</h1><h2 id="4-1-数据集选择"><a href="#4-1-数据集选择" class="headerlink" title="4.1 数据集选择"></a>4.1 数据集选择</h2><p>数据集一共有4个，如前所述，有三个图是实际生活中代表不同安全应用（Facebook，Enron，Epinions），用的合成的恶意节点；以及一个现实世界的大规模Twitter图上，用的真实的恶意节点。<br>前三个图的获得是从SNAP上，从SNAP上获得了每个图的最大连通分量。（<a href="http://snap.stanford.edu/data/index.html" target="_blank" rel="noopener">http://snap.stanford.edu/data/index.html</a>）得到的数据集中都是负节点，因此用人工合成的方式得到正节点。这一过程的理论依据和实际操作可以参考引用2，25，67，总之依据的是基于图的安全分析。特别指出，为了防止正负节点的结构不同产生影响，直接复制负节点和他的边，作为正节点的边。此外，假设攻击者已经在正节点和负节点间插入了一些边，称为攻击边。<br>这个Twitter图是无向图（代表互关），自带正节点和攻击边。总之包括正节点，负节点和没有标记的点。<br>对于每一个合成正节点的图，随机选取100个正节点和100个 负节点作为训练集。对于Twitter图，随机选3000个正节点和3000个 负节点作为训练集，剩下的有标签的节点组成测试集。训练集相对较小是没关系的，因为基于图的分类就是这样假设的。对于三个合成正节点的图，默认都是随机加了10K的攻击边。</p>
<h2 id="4-2-攻击者的目标节点选取"><a href="#4-2-攻击者的目标节点选取" class="headerlink" title="4.2 攻击者的目标节点选取"></a>4.2 攻击者的目标节点选取</h2><p>设计了三种选取目标节点的方法。<br>1）RAND：从正节点里面随机选取。<br>2）connected component：选择和正节点相连的正节点。攻击者先从正节点当中随机选一个，然后攻击者用宽度优先去找和它相连的其他正节点。<br>3）CLOSE：选和负节点距离近的正节点。应用了closeness centrality的变体来度量正节点和负节点间的距离。具体而言，计算正节点和所有负节点的距离和的倒数作为正节点的closeness centrality。然后选择这个数值小的正节点作为目标节点。<br>通过第二种方式选出来的目标节点结构更相似，如果一个可以规避检测，那么其他的也很容易；第三种方式因为和负节点近，因此也比较容易规避检测。所以预期的结果应该是第一种方式效果最差。</p>
<h2 id="4-3-模拟代价"><a href="#4-3-模拟代价" class="headerlink" title="4.3 模拟代价"></a>4.3 模拟代价</h2><p>关于增删边的代价 ，模拟生活中多种场景，提出了三种方案。<br>1）Equal cost：对任意节点组合的增删代价都是一样的 ，赋值为1。<br>2）Uniform cost：不同节点组合的增删代价在一个区间内是均匀分布的。本实验中设定的给每一个节点对在区间1到10随机抽样赋值。<br>3）Categorical cost：节点组合分为三类，每一类赋相同的值。第一类是在正节点和正节点之间，赋一个较小的值，比如1；第二类是在正节点和一个被社工搞定的负节点之间，可以赋值为10；第三类是在负节点和剩下的正节点之间，可以赋值为100。随机抽了100个负节点作为被社工搞定的负节点。</p>
<h2 id="4-4-对照实验组"><a href="#4-4-对照实验组" class="headerlink" title="4.4 对照实验组"></a>4.4 对照实验组</h2><p>为攻击设置了三组对照试验组。<br>1）随机攻击：对于每一个目标节点，随机选择K个节点，改变节点u和每一个被选中的节点的连接状态。<br>2）Del-Add攻击：假设目标节点和d个正节点相连，如果d大于K，就随机删除K条边；如果d小于K，就先删除的d条边，然后在目标节点和K-d个随机选出的负节点之间加边。这样做的直觉解释是对于一个目标节点而言，如果和其他正节点连接较少，而和负节点连接较多，那么它更有可能被误分类成负节点。<br>3）一个比较新的为GCN设计的攻击方式。在本文的4.8讲述。</p>
<h2 id="4-5-全知识下的实验结论"><a href="#4-5-全知识下的实验结论" class="headerlink" title="4.5 全知识下的实验结论"></a>4.5 全知识下的实验结论</h2><p>全知识背景下，有7个影响攻击结果的参数：代价类型，选择目标节点方式，攻击边的个数，目标节点的个数，节点改动边最大值K，超参数$\lambda$（拉格朗日因子）和超参数$\eta$。当考察某一个参数的影响时，会固定其余参数为默认值。<br>实验结论：1）攻击是有效的，效果明显好于对照攻击组。2）攻击插入边比删除边更多，这是因为原图比较稀疏，增边余地更大。在Facebook图上的效果最差也是因为Facebook图最稠密，节点的度最高，比较鲁棒。3）关于不同代价类型的影响，Equal cost效果最好，Categorical cost效果最差，因为Equal cost代价都比较小，使得攻击操作选择余地更大。但是即使对于Categorical cost，攻击也仍然很有效。4）目标节点选取方式，RAND效果最差，原因如前所述的直觉想法。5）K的影响：FNR随着K的增加而增加，因为K越大，允许操作者做的操作越多，总代价几乎随K线性增长。6）攻击边个数的影响：攻击边越多，FNR越高，但这是因为collective classification的分类准确性本来就是随着攻击边个数增多而下降，即使不存在攻击。7）目标节点个数的影响：对不同的目标节点个数，FNR结果比较稳定，这是因为对于每一个目标节点，攻击过程是迭代计算来改变边的。另一方面，目标节点多的话，总代价会高。8）超参数的影响：对于$\lambda$和$\eta$，在FNR关于超参数变化的曲线上，都可以观察到相移现象。当超参数大于某个特定阈值时，攻击效果很好而且攻击效果对超参数的变化不敏感了，当小于这个阈值时，攻击效果不太好。Facebook图的阈值比较小，这可能是因为它更稠密。</p>
<h2 id="4-6-部分知识下的实验结论"><a href="#4-6-部分知识下的实验结论" class="headerlink" title="4.6 部分知识下的实验结论"></a>4.6 部分知识下的实验结论</h2><p>设计了四个情景。对于不知道的知识，都是随机抽样假设。具体内容和结论这里就略了。<br>1）Parameter=No,Training=Yes,Graph=Complete<br>2）Parameter=Yes,Training=No,Graph=Complete<br>3）Parameter=Yes,Training=Yes,Graph=Partial<br>4）Parameter=No,Training=No,Graph=Partial</p>
<h2 id="4-7-移植性"><a href="#4-7-移植性" class="headerlink" title="4.7 移植性"></a>4.7 移植性</h2><p>在CC和GNN的各种方法上做了实验，结论当然是对LinLBP效果最好。可以移植到其他基于图的分类方法，但效果差别很大。对CC的移植性普遍比GNN好，其中，GCN的效果最差，这可能是因为GCN使用复杂的图卷积来利用图结构中的高阶相关性，因此对边的改动更鲁棒。</p>
<h2 id="4-8-和Nettack的比较"><a href="#4-8-和Nettack的比较" class="headerlink" title="4.8 和Nettack的比较"></a>4.8 和Nettack的比较</h2><p>如前所述，Nettack定义了一个保留扰动的图结构有一些限制，要求攻击前后，图的节点度分布应该是相似的。然后Nettack学习了一个GCN的替代线性模型。Nettack有两个版本，一个版本仅仅改变图结构，另一种也会改变一些节点属性。论文中拿来作对比实验的是第一个版本。Nettack也是假设不同的边具有相同的代价的。</p>
<h1 id="5-未来方向"><a href="#5-未来方向" class="headerlink" title="5 未来方向"></a>5 未来方向</h1><p>1）对其他基于图的分类的攻击。论文中选择LinLBP的原因是对所有边分配一样的权重，使得优化问题更好解。在基于RW的方法和JWP中，边的权重或者传播取决于图的结构。因此优化对抗矩阵就更难，因为对抗矩阵的梯度同样取决于边的权重，而边的权重又是关于对抗矩阵的函数的一部分。但这仍是未来的一个方向。<br>2）不可用性攻击。这篇论文主要集中于FNR。但同时攻击者也可以从不可用性的角度下手，即提高FPR。尽管本论文关注的是FNR，作者也做了实验证明可以轻微的影响FPR。<br>3）毒化训练集。攻击者还可以通过毒化训练集来攻击基于图的分类。比如在某些应用中，训练集是动态获得更新的，所以攻击者可以通过举报正常用户为欺诈用户来毒化训练集。<br>4）对策。对于论文提出的这类攻击，有两个方向的对策，一是预防，二是检测。关于预防，可以探索从设计上就对操纵图结构更鲁棒的基于图的分类方法。关于检测，可以设计方法来检测对图结构的修改。比如可以对每个节点对提取特征，然后训练一个二元分类器，来预测节点对间的连接是否被修改。此外，注意到是实施攻击后可能改变了正节点的本地结构，攻击后目标节点的聚类系数有稍微的下降，这可能是因为攻击过程中给目标节点增加了邻居，但是这些邻居之间没有相连。也许未来可以根据这样的本地结构来检测正节点和攻击。<br>5）对图级别的分类方法的攻击。本篇论文规避的是节点级别的分类方法。在一些安全分析中有的也应用了图级别的分类方法，比如一些方法提出分析控制流图并用于分类来进行恶意检测。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/" data-id="ckab75xm40000xocpargdd0lg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">图神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 10px;">对抗攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" style="font-size: 15px;">对抗样本生成</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/17/paper4/">论文笔记：4   Attacking Graph-based Classification via Manipulating the Graph Structure</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/16/paper3/">论文笔记：3   Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/15/paper2/">论文笔记：2   Fooling automated surveillance cameras：adversarial patches to attack person detection</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/paper1/">论文笔记：1   Face-Off：Adversarial Face Obfuscation</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/14/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Meiyi Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.css">

  
<script src="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.pack.js"></script>




<script src="https://heqi867610481.github.io/KingNothing.github.io/js/script.js"></script>




  </div>
</body>
</html>