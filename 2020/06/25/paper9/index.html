<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>论文笔记：9   Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment | </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1 论文总体思路本文实施了模型反演攻击，即攻击者意图从模型的预测值来推断模型的训练数据和测试数据。实施攻击采用的方法是再训练一个神经网络作为目标模型的反演模型。训练反演模型本文提出了两个技巧：1）利用攻击者的背景知识构建一个辅助数据集，而不需要得到受害者模型的训练集。2）设计了一种基于截断的技术，从而可以利用受害者模型的经过截断的部分预测值来实施模型反演。本文证实即使对于黑盒受害者模型的数据集仅有">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：9   Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment">
<meta property="og:url" content="https://heqi867610481.github.io/KingNothing.github.io/2020/06/25/paper9/index.html">
<meta property="og:site_name">
<meta property="og:description" content="1 论文总体思路本文实施了模型反演攻击，即攻击者意图从模型的预测值来推断模型的训练数据和测试数据。实施攻击采用的方法是再训练一个神经网络作为目标模型的反演模型。训练反演模型本文提出了两个技巧：1）利用攻击者的背景知识构建一个辅助数据集，而不需要得到受害者模型的训练集。2）设计了一种基于截断的技术，从而可以利用受害者模型的经过截断的部分预测值来实施模型反演。本文证实即使对于黑盒受害者模型的数据集仅有">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/13.jpg">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/14.jpg">
<meta property="og:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/15.jpg">
<meta property="article:published_time" content="2020-06-25T13:29:07.000Z">
<meta property="article:modified_time" content="2020-06-27T03:03:12.581Z">
<meta property="article:author" content="Meiyi Jiang">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/13.jpg">
  
    <link rel="alternate" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="https://heqi867610481.github.io/KingNothing.github.io/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/">Home</a>
        
          <a class="main-nav-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://heqi867610481.github.io/KingNothing.github.io/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://heqi867610481.github.io/KingNothing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-paper9" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/25/paper9/" class="article-date">
  <time datetime="2020-06-25T13:29:07.000Z" itemprop="datePublished">2020-06-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      论文笔记：9   Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-论文总体思路"><a href="#1-论文总体思路" class="headerlink" title="1 论文总体思路"></a>1 论文总体思路</h1><p>本文实施了模型反演攻击，即攻击者意图从模型的预测值来推断模型的训练数据和测试数据。实施攻击采用的方法是再训练一个神经网络作为目标模型的反演模型。训练反演模型本文提出了两个技巧：1）利用攻击者的背景知识构建一个辅助数据集，而不需要得到受害者模型的训练集。2）设计了一种基于截断的技术，从而可以利用受害者模型的经过截断的部分预测值来实施模型反演。本文证实即使对于黑盒受害者模型的数据集仅有部分知识以及仅知道经过截断的预测值，反演模型仍然可以有着较好的表现，超越前人的方法。<br>模型反演是意图从模型的预测值当中获取训练数据的相关信息的技术，大致可分为两类：1）基于优化的方法，在数据空间中利用基于梯度的优化方法来反演模型。比如文中引用的文献21的MIA方法，就是把反演任务作为一个优化问题去找给定类别的最优数据。此方法对于简单的网络有效，但是被证明对于复杂的网络效果不佳，这可能是因为优化目标并没有真正抓住数据空间的语义信息。2）基于训练的方法，通过训练另一个表现为受害模型的反演的模型来实现。目标在于用包括神经网络每层的激活在内的计算机视觉特征来重构图片。<br>对于模型反演攻击的目标又可细分为两类：1）数据重构。给出分类器的预测向量，需要重构出这个未知的数据。比如对于人脸识别系统而言，就给出一个人的身份要求重构出此人的面部图片。2）训练类别推断。要求对于分类器的每个类别恢复一个语义上有意义可识别的数据。<br>本文设置的攻击者背景大多数情况是黑盒的，采用的是基于训练的攻击。为了解决不能得到训练数据的问题，方法是基于背景知识从一个更通用的数据分布中形成辅助数据集。这些辅助样本也保留有更通用普遍的特征。文中还有一个实验表明，即使在一些场合下攻击者可以获得受害模型的训练集，用通用样本对训练集做数据增强也能很好的提升准确率。<br>前面提到本文采用基于截断的方法来训练反演模型，核心思想是在训练过程中用截断后的预测输入。截断还能帮助减小过拟合。比如对于第二个问题训练类别推断，在训练过程中，直接将预测截断成独热向量来输入。这样训练出的反演模型可以由独热向量生成图片。<br>设计攻击者模型时考虑以下场景：1）攻击者是个普通用户，模型对他而言是个黑盒。2）攻击者即是开发者，那么反演模型就可以和分类器在同一个训练集上一起联合训练，这样产生的反演模型更精确。这种情况下，目标是迫使分类器的预测值也保留帮助反演模型重构数据的重要信息。使用反演模型的重构损失来限制分类器的训练。</p>
<h1 id="2-背景知识"><a href="#2-背景知识" class="headerlink" title="2 背景知识"></a>2 背景知识</h1><h2 id="2-1-模型反演"><a href="#2-1-模型反演" class="headerlink" title="2.1 模型反演"></a>2.1 模型反演</h2><p>通常计算机视觉领域的模型反演用图片的计算机视觉特征比如HOG和SIFT，或者用网络每一层的激活来重构图片。前面提到分成两种，基于优化的和基于训练的。基于优化的往往需要对白盒模型实施，而且对于大型神经网络倾向于生成不像自然图片的图片。此外因为要计算梯度，因此在测试集上也是很费时的。而基于训练的方法只在训练反演模型时耗时，而训练完在测试集上就很快。</p>
<h2 id="2-2-转置卷积（反卷积）"><a href="#2-2-转置卷积（反卷积）" class="headerlink" title="2.2 转置卷积（反卷积）"></a>2.2 转置卷积（反卷积）</h2><p>这个是构建反演模型的基础，本文并没有对其原理详细解释，只是应用了现成的模型。这里补充下转置卷积的原理。<br><a href="https://blog.csdn.net/lanadeus/article/details/82534425" target="_blank" rel="noopener">https://blog.csdn.net/lanadeus/article/details/82534425</a><br>首先转置卷积是一种上采样方法。上采样比如用来提高图片的分辨率。常见的方法有最近邻插值，双线性插值，双立方插值。这些方法不涉及到学习过程。如果想利用神经网络进行上采样，就需要使用转置卷积。<br>首先考虑正向的卷积操作。给定一个input，一个kernel，得出一个output矩阵。事实上，这一个过程可以表示为矩阵乘法，当然参与乘法的矩阵是经过数值重新排列以及0填充的。（详细过程见链接）。因此可以想象，两边同乘由kernel衍生矩阵的转置那样的维度的矩阵，就能实现卷积的逆过程。卷积是个多对一的过程，而转置卷积则是一对多。从信息论的角度看,卷积是不可逆的。所以这里说的并不是从output矩阵和kernel矩阵计算出原始的input矩阵。而是计算出一个保持了位置性关系的矩阵。也就是说用来进行转置卷积的权重矩阵不一定来自于原卷积矩阵。重点是权重矩阵的形状和转置后的卷积矩阵相同。需要注意的是，转置卷积会在生成的图像中造成棋盘效应。可以在使用转置卷积进行上采样操作之后再过一个普通的卷积来减轻此类问题。</p>
<h1 id="3-攻击者模型"><a href="#3-攻击者模型" class="headerlink" title="3 攻击者模型"></a>3 攻击者模型</h1><p>为攻击者设计了三个攻击场景。1）对黑盒分类器基于截断向量进行数据重构。2）对黑盒分类器进行功能推断。3）恶意开发者意图构造能帮助重构用户输入数据的分类器。</p>
<h2 id="3-1-场景一"><a href="#3-1-场景一" class="headerlink" title="3.1 场景一"></a>3.1 场景一</h2><p>这种情景下，攻击者不知道受害模型训练集的分布，架构以及参数，但是有一些最基础的背景知识。比如攻击者知道这大概是一个人脸识别的分类器，这样他可以从一个更通用的分布中获得样本。攻击者还知道分类器的输入格式和输出格式（输出向量的维度）。关于输出维度，对于被截断的向量也是可行的。因为可以用一系列输入数据送去查询然后发现一共都有哪些类。这个场景下给出一个被截断的预测向量f，攻击者要找到一个最合适的数据使得被分类器分类结果仍是f。</p>
<h2 id="3-2-场景二"><a href="#3-2-场景二" class="headerlink" title="3.2 场景二"></a>3.2 场景二</h2><p>与前者不同，给出一个类别y，攻击者意图找到该类的代表性数据，也就是找到一个数据使得被分类器分为类别y。</p>
<h2 id="3-3-场景三"><a href="#3-3-场景三" class="headerlink" title="3.3 场景三"></a>3.3 场景三</h2><p>这场景下，攻击者即开发者，知道模型的训练集，架构，参数。攻击者可以获得用户的被截断的预测向量，然后试图重构用户输入数据。攻击者的目标是还保证原模型的分类准确率的情况下，同时尽量提高数据重构的质量。</p>
<h1 id="4-实施方法"><a href="#4-实施方法" class="headerlink" title="4 实施方法"></a>4 实施方法</h1><h2 id="4-1-辅助数据集（没啥好说的，略）"><a href="#4-1-辅助数据集（没啥好说的，略）" class="headerlink" title="4.1 辅助数据集（没啥好说的，略）"></a>4.1 辅助数据集（没啥好说的，略）</h2><h2 id="4-2-反演模型的截断方法"><a href="#4-2-反演模型的截断方法" class="headerlink" title="4.2 反演模型的截断方法"></a>4.2 反演模型的截断方法</h2><p><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/13.jpg" alt="反演模型训练过程"><br>对于辅助集的样本，截断他们的预测向量到同样的维度，然后作为输入来训练反演模型，这样可以迫使用截断的预测来重构数据。反演模型训练时候最小化的目标函数表示如下。<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/14.jpg" alt="公式"><br>其中a是出自辅助集的样本，R是损失函数，本文中用的是L2。这个截断过程，可以看作是正向训练的特征选择过程，去除不重要的特征，所以也就能理解为什么这一步能减少反演模型的过拟合。对于前文提到的攻击场景二，训练类别推断，可以看作向量被截断成维度为1。</p>
<h2 id="4-3-联合训练分类器和反演模型"><a href="#4-3-联合训练分类器和反演模型" class="headerlink" title="4.3 联合训练分类器和反演模型"></a>4.3 联合训练分类器和反演模型</h2><p>这种情况下，除了训练分类器的损失函数，还有重构损失函数，描述如下：<br><img src="https://heqi867610481.github.io/KingNothing.github.io/KingNothing.github.io/2020/06/25/paper9/images/15.jpg" alt="公式"><br>其中，D是训练集。直觉上解释，有了这个重构损失能使得分类器的预测倾向于保留有重要的信息。实验过程中发现直接使用预测向量效果不够好，这是因为输出被softmax限制在了0~1，这实际上削弱了输出的激活，造成了信息损失。为了解决这个问题，将输出的预测向量重新缩放到一个更大的范围，其中的参数在训练反演模型过程中优化。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://heqi867610481.github.io/KingNothing.github.io/2020/06/25/paper9/" data-id="ckczzvb1x00015kcp8am255zj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/28/paper10/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          论文笔记：10   Latent Backdoor Attacks on Deep Neural Networks
        
      </div>
    </a>
  
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/15/paper8/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文笔记：8   CloudLeak：Large-Scale Deep Learning Models Stealing Through Adversarial Examples</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" rel="tag">人脸识别</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" rel="tag">后门攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BC%A9%E6%94%BE%E7%AE%97%E6%B3%95/" rel="tag">图像缩放算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">图神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" rel="tag">对抗攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" rel="tag">对抗样本生成</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 13.33px;">人脸识别</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" style="font-size: 10px;">后门攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BC%A9%E6%94%BE%E7%AE%97%E6%B3%95/" style="font-size: 10px;">图像缩放算法</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">图神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/" style="font-size: 13.33px;">对抗攻击</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/" style="font-size: 16.67px;">对抗样本生成</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 13.33px;">目标检测</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a> <a href="https://heqi867610481.github.io/KingNothing.github.io/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="https://heqi867610481.github.io/KingNothing.github.io/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/28/paper10/">论文笔记：10   Latent Backdoor Attacks on Deep Neural Networks</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/25/paper9/">论文笔记：9   Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/15/paper8/">论文笔记：8   CloudLeak：Large-Scale Deep Learning Models Stealing Through Adversarial Examples</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/06/10/paper7/">[object Object]</a>
          </li>
        
          <li>
            <a href="https://heqi867610481.github.io/KingNothing.github.io/2020/05/30/paper6/">论文笔记：6   Seeing isn’t Believing Towards More Robust Adversarial Attack Against Real World Object Detectors</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Meiyi Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="https://heqi867610481.github.io/KingNothing.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.css">

  
<script src="https://heqi867610481.github.io/KingNothing.github.io/fancybox/jquery.fancybox.pack.js"></script>




<script src="https://heqi867610481.github.io/KingNothing.github.io/js/script.js"></script>




  </div>
</body>
</html>